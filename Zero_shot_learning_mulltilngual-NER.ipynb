{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from seqeval.metrics import f1_score\n",
    "from transformers import EvalPrediction\n",
    "\n",
    "from transformers import TrainingArguments\n",
    "from datasets import get_dataset_config_names\n",
    "from datasets import load_dataset\n",
    "\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "from collections import defaultdict\n",
    "from datasets import DatasetDict\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from transformers import Trainer\n",
    "\n",
    "import torch.nn as nn\n",
    "from matplotlib import pyplot as plt\n",
    "from transformers import XLMRobertaConfig\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "from transformers.models.roberta.modeling_roberta import RobertaModel\n",
    "from transformers.models.roberta.modeling_roberta import RobertaPreTrainedModel\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import AutoConfig\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from seqeval.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XTREME has 183 configurations\n"
     ]
    }
   ],
   "source": [
    "xtreme_subsets = get_dataset_config_names(\"xtreme\")\n",
    "print(f\"XTREME has {len(xtreme_subsets)} configurations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['XNLI',\n",
       " 'tydiqa',\n",
       " 'SQuAD',\n",
       " 'PAN-X.af',\n",
       " 'PAN-X.ar',\n",
       " 'PAN-X.bg',\n",
       " 'PAN-X.bn',\n",
       " 'PAN-X.de',\n",
       " 'PAN-X.el',\n",
       " 'PAN-X.en',\n",
       " 'PAN-X.es',\n",
       " 'PAN-X.et',\n",
       " 'PAN-X.eu',\n",
       " 'PAN-X.fa',\n",
       " 'PAN-X.fi',\n",
       " 'PAN-X.fr',\n",
       " 'PAN-X.he',\n",
       " 'PAN-X.hi',\n",
       " 'PAN-X.hu',\n",
       " 'PAN-X.id',\n",
       " 'PAN-X.it',\n",
       " 'PAN-X.ja',\n",
       " 'PAN-X.jv',\n",
       " 'PAN-X.ka',\n",
       " 'PAN-X.kk',\n",
       " 'PAN-X.ko',\n",
       " 'PAN-X.ml',\n",
       " 'PAN-X.mr',\n",
       " 'PAN-X.ms',\n",
       " 'PAN-X.my',\n",
       " 'PAN-X.nl',\n",
       " 'PAN-X.pt',\n",
       " 'PAN-X.ru',\n",
       " 'PAN-X.sw',\n",
       " 'PAN-X.ta',\n",
       " 'PAN-X.te',\n",
       " 'PAN-X.th',\n",
       " 'PAN-X.tl',\n",
       " 'PAN-X.tr',\n",
       " 'PAN-X.ur',\n",
       " 'PAN-X.vi',\n",
       " 'PAN-X.yo',\n",
       " 'PAN-X.zh',\n",
       " 'MLQA.ar.ar',\n",
       " 'MLQA.ar.de',\n",
       " 'MLQA.ar.vi',\n",
       " 'MLQA.ar.zh',\n",
       " 'MLQA.ar.en',\n",
       " 'MLQA.ar.es',\n",
       " 'MLQA.ar.hi',\n",
       " 'MLQA.de.ar',\n",
       " 'MLQA.de.de',\n",
       " 'MLQA.de.vi',\n",
       " 'MLQA.de.zh',\n",
       " 'MLQA.de.en',\n",
       " 'MLQA.de.es',\n",
       " 'MLQA.de.hi',\n",
       " 'MLQA.vi.ar',\n",
       " 'MLQA.vi.de',\n",
       " 'MLQA.vi.vi',\n",
       " 'MLQA.vi.zh',\n",
       " 'MLQA.vi.en',\n",
       " 'MLQA.vi.es',\n",
       " 'MLQA.vi.hi',\n",
       " 'MLQA.zh.ar',\n",
       " 'MLQA.zh.de',\n",
       " 'MLQA.zh.vi',\n",
       " 'MLQA.zh.zh',\n",
       " 'MLQA.zh.en',\n",
       " 'MLQA.zh.es',\n",
       " 'MLQA.zh.hi',\n",
       " 'MLQA.en.ar',\n",
       " 'MLQA.en.de',\n",
       " 'MLQA.en.vi',\n",
       " 'MLQA.en.zh',\n",
       " 'MLQA.en.en',\n",
       " 'MLQA.en.es',\n",
       " 'MLQA.en.hi',\n",
       " 'MLQA.es.ar',\n",
       " 'MLQA.es.de',\n",
       " 'MLQA.es.vi',\n",
       " 'MLQA.es.zh',\n",
       " 'MLQA.es.en',\n",
       " 'MLQA.es.es',\n",
       " 'MLQA.es.hi',\n",
       " 'MLQA.hi.ar',\n",
       " 'MLQA.hi.de',\n",
       " 'MLQA.hi.vi',\n",
       " 'MLQA.hi.zh',\n",
       " 'MLQA.hi.en',\n",
       " 'MLQA.hi.es',\n",
       " 'MLQA.hi.hi',\n",
       " 'XQuAD.ar',\n",
       " 'XQuAD.de',\n",
       " 'XQuAD.vi',\n",
       " 'XQuAD.zh',\n",
       " 'XQuAD.en',\n",
       " 'XQuAD.es',\n",
       " 'XQuAD.hi',\n",
       " 'XQuAD.el',\n",
       " 'XQuAD.ru',\n",
       " 'XQuAD.th',\n",
       " 'XQuAD.tr',\n",
       " 'bucc18.de',\n",
       " 'bucc18.fr',\n",
       " 'bucc18.zh',\n",
       " 'bucc18.ru',\n",
       " 'PAWS-X.de',\n",
       " 'PAWS-X.en',\n",
       " 'PAWS-X.es',\n",
       " 'PAWS-X.fr',\n",
       " 'PAWS-X.ja',\n",
       " 'PAWS-X.ko',\n",
       " 'PAWS-X.zh',\n",
       " 'tatoeba.afr',\n",
       " 'tatoeba.ara',\n",
       " 'tatoeba.ben',\n",
       " 'tatoeba.bul',\n",
       " 'tatoeba.deu',\n",
       " 'tatoeba.cmn',\n",
       " 'tatoeba.ell',\n",
       " 'tatoeba.est',\n",
       " 'tatoeba.eus',\n",
       " 'tatoeba.fin',\n",
       " 'tatoeba.fra',\n",
       " 'tatoeba.heb',\n",
       " 'tatoeba.hin',\n",
       " 'tatoeba.hun',\n",
       " 'tatoeba.ind',\n",
       " 'tatoeba.ita',\n",
       " 'tatoeba.jav',\n",
       " 'tatoeba.jpn',\n",
       " 'tatoeba.kat',\n",
       " 'tatoeba.kaz',\n",
       " 'tatoeba.kor',\n",
       " 'tatoeba.mal',\n",
       " 'tatoeba.mar',\n",
       " 'tatoeba.nld',\n",
       " 'tatoeba.pes',\n",
       " 'tatoeba.por',\n",
       " 'tatoeba.rus',\n",
       " 'tatoeba.spa',\n",
       " 'tatoeba.swh',\n",
       " 'tatoeba.tam',\n",
       " 'tatoeba.tel',\n",
       " 'tatoeba.tgl',\n",
       " 'tatoeba.tha',\n",
       " 'tatoeba.tur',\n",
       " 'tatoeba.urd',\n",
       " 'tatoeba.vie',\n",
       " 'udpos.Afrikaans',\n",
       " 'udpos.Arabic',\n",
       " 'udpos.Basque',\n",
       " 'udpos.Bulgarian',\n",
       " 'udpos.Dutch',\n",
       " 'udpos.English',\n",
       " 'udpos.Estonian',\n",
       " 'udpos.Finnish',\n",
       " 'udpos.French',\n",
       " 'udpos.German',\n",
       " 'udpos.Greek',\n",
       " 'udpos.Hebrew',\n",
       " 'udpos.Hindi',\n",
       " 'udpos.Hungarian',\n",
       " 'udpos.Indonesian',\n",
       " 'udpos.Italian',\n",
       " 'udpos.Japanese',\n",
       " 'udpos.Kazakh',\n",
       " 'udpos.Korean',\n",
       " 'udpos.Chinese',\n",
       " 'udpos.Marathi',\n",
       " 'udpos.Persian',\n",
       " 'udpos.Portuguese',\n",
       " 'udpos.Russian',\n",
       " 'udpos.Spanish',\n",
       " 'udpos.Tagalog',\n",
       " 'udpos.Tamil',\n",
       " 'udpos.Telugu',\n",
       " 'udpos.Thai',\n",
       " 'udpos.Turkish',\n",
       " 'udpos.Urdu',\n",
       " 'udpos.Vietnamese',\n",
       " 'udpos.Yoruba']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtreme_subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PAN-X.af',\n",
       " 'PAN-X.ar',\n",
       " 'PAN-X.bg',\n",
       " 'PAN-X.bn',\n",
       " 'PAN-X.de',\n",
       " 'PAN-X.el',\n",
       " 'PAN-X.en',\n",
       " 'PAN-X.es',\n",
       " 'PAN-X.et',\n",
       " 'PAN-X.eu',\n",
       " 'PAN-X.fa',\n",
       " 'PAN-X.fi',\n",
       " 'PAN-X.fr',\n",
       " 'PAN-X.he',\n",
       " 'PAN-X.hi',\n",
       " 'PAN-X.hu',\n",
       " 'PAN-X.id',\n",
       " 'PAN-X.it',\n",
       " 'PAN-X.ja',\n",
       " 'PAN-X.jv',\n",
       " 'PAN-X.ka',\n",
       " 'PAN-X.kk',\n",
       " 'PAN-X.ko',\n",
       " 'PAN-X.ml',\n",
       " 'PAN-X.mr',\n",
       " 'PAN-X.ms',\n",
       " 'PAN-X.my',\n",
       " 'PAN-X.nl',\n",
       " 'PAN-X.pt',\n",
       " 'PAN-X.ru',\n",
       " 'PAN-X.sw',\n",
       " 'PAN-X.ta',\n",
       " 'PAN-X.te',\n",
       " 'PAN-X.th',\n",
       " 'PAN-X.tl',\n",
       " 'PAN-X.tr',\n",
       " 'PAN-X.ur',\n",
       " 'PAN-X.vi',\n",
       " 'PAN-X.yo',\n",
       " 'PAN-X.zh']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panx_subset = [s for s in xtreme_subsets if s.startswith('PAN')]\n",
    "panx_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset xtreme (/home/raj/.cache/huggingface/datasets/xtreme/PAN-X.de/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "249c8b038f1d4169b912893496ca6076",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset('xtreme',name='PAN-X.de')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs'],\n",
       "        num_rows: 20000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = ['de','fr','it','en']\n",
    "#de : Germen, fr: france, it:Italian, en: English\n",
    "prercentage_lang_spoken = [0.629,0.229,0.084,0.059]\n",
    "\n",
    "panx_ds_combined = defaultdict(DatasetDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(datasets.dataset_dict.DatasetDict, {})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panx_ds_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset xtreme (/home/raj/.cache/huggingface/datasets/xtreme/PAN-X.de/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12770bb603df4f27a8886827454eb2b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /home/raj/.cache/huggingface/datasets/xtreme/PAN-X.de/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-e5ddf09f1ae095ec.arrow\n",
      "Loading cached shuffled indices for dataset at /home/raj/.cache/huggingface/datasets/xtreme/PAN-X.de/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-25e7e2dd003d0fa6.arrow\n",
      "Loading cached shuffled indices for dataset at /home/raj/.cache/huggingface/datasets/xtreme/PAN-X.de/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-73a95bc0accfea8b.arrow\n",
      "Found cached dataset xtreme (/home/raj/.cache/huggingface/datasets/xtreme/PAN-X.fr/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f464571d05c4a34b66ea80b81ec35e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /home/raj/.cache/huggingface/datasets/xtreme/PAN-X.fr/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-6ff29513007ec78b.arrow\n",
      "Loading cached shuffled indices for dataset at /home/raj/.cache/huggingface/datasets/xtreme/PAN-X.fr/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-c5c9a4fc19dfd7d6.arrow\n",
      "Loading cached shuffled indices for dataset at /home/raj/.cache/huggingface/datasets/xtreme/PAN-X.fr/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-9711ab25936b81b7.arrow\n",
      "Found cached dataset xtreme (/home/raj/.cache/huggingface/datasets/xtreme/PAN-X.it/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0188165239474e25a6737275f398855f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /home/raj/.cache/huggingface/datasets/xtreme/PAN-X.it/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-daa9a1770078307c.arrow\n",
      "Loading cached shuffled indices for dataset at /home/raj/.cache/huggingface/datasets/xtreme/PAN-X.it/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-5e244c05031bab3c.arrow\n",
      "Loading cached shuffled indices for dataset at /home/raj/.cache/huggingface/datasets/xtreme/PAN-X.it/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-497ee15c12bff58d.arrow\n",
      "Found cached dataset xtreme (/home/raj/.cache/huggingface/datasets/xtreme/PAN-X.en/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fd867fb30f545beb390adf1b2be2a34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /home/raj/.cache/huggingface/datasets/xtreme/PAN-X.en/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-757845faa9fa6949.arrow\n",
      "Loading cached shuffled indices for dataset at /home/raj/.cache/huggingface/datasets/xtreme/PAN-X.en/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-305cefc7ffa49fd9.arrow\n",
      "Loading cached shuffled indices for dataset at /home/raj/.cache/huggingface/datasets/xtreme/PAN-X.en/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-e5ec5e6ba7c1237d.arrow\n"
     ]
    }
   ],
   "source": [
    "for lang,percentage in zip(languages,prercentage_lang_spoken):\n",
    "    ds = load_dataset('xtreme',name=f'PAN-X.{lang}')\n",
    "    for train_test_val in ds:\n",
    "        panx_ds_combined[lang][train_test_val] = (\n",
    "            ds[train_test_val].shuffle(seed=0).select(range(int(percentage*ds[train_test_val].num_rows)))\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(datasets.dataset_dict.DatasetDict,\n",
       "            {'de': DatasetDict({\n",
       "                 train: Dataset({\n",
       "                     features: ['tokens', 'ner_tags', 'langs'],\n",
       "                     num_rows: 12580\n",
       "                 })\n",
       "                 validation: Dataset({\n",
       "                     features: ['tokens', 'ner_tags', 'langs'],\n",
       "                     num_rows: 6290\n",
       "                 })\n",
       "                 test: Dataset({\n",
       "                     features: ['tokens', 'ner_tags', 'langs'],\n",
       "                     num_rows: 6290\n",
       "                 })\n",
       "             }),\n",
       "             'fr': DatasetDict({\n",
       "                 train: Dataset({\n",
       "                     features: ['tokens', 'ner_tags', 'langs'],\n",
       "                     num_rows: 4580\n",
       "                 })\n",
       "                 validation: Dataset({\n",
       "                     features: ['tokens', 'ner_tags', 'langs'],\n",
       "                     num_rows: 2290\n",
       "                 })\n",
       "                 test: Dataset({\n",
       "                     features: ['tokens', 'ner_tags', 'langs'],\n",
       "                     num_rows: 2290\n",
       "                 })\n",
       "             }),\n",
       "             'it': DatasetDict({\n",
       "                 train: Dataset({\n",
       "                     features: ['tokens', 'ner_tags', 'langs'],\n",
       "                     num_rows: 1680\n",
       "                 })\n",
       "                 validation: Dataset({\n",
       "                     features: ['tokens', 'ner_tags', 'langs'],\n",
       "                     num_rows: 840\n",
       "                 })\n",
       "                 test: Dataset({\n",
       "                     features: ['tokens', 'ner_tags', 'langs'],\n",
       "                     num_rows: 840\n",
       "                 })\n",
       "             }),\n",
       "             'en': DatasetDict({\n",
       "                 train: Dataset({\n",
       "                     features: ['tokens', 'ner_tags', 'langs'],\n",
       "                     num_rows: 1180\n",
       "                 })\n",
       "                 validation: Dataset({\n",
       "                     features: ['tokens', 'ner_tags', 'langs'],\n",
       "                     num_rows: 590\n",
       "                 })\n",
       "                 test: Dataset({\n",
       "                     features: ['tokens', 'ner_tags', 'langs'],\n",
       "                     num_rows: 590\n",
       "                 })\n",
       "             })})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panx_ds_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>de</th>\n",
       "      <th>fr</th>\n",
       "      <th>it</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12580</td>\n",
       "      <td>4580</td>\n",
       "      <td>1680</td>\n",
       "      <td>1180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      de    fr    it    en\n",
       "0  12580  4580  1680  1180"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame({lang: [ panx_ds_combined[lang]['train'].num_rows] for lang in languages })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'ner_tags': Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], id=None), length=-1, id=None), 'langs': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)}\n",
      "tokens:['2.000', 'Einwohnern', 'an', 'der', 'Danziger', 'Bucht', 'in', 'der', 'polnischen', 'Woiwodschaft', 'Pommern', '.']\n",
      "ner_tags:[0, 0, 0, 0, 5, 6, 0, 0, 5, 5, 6, 0]\n",
      "langs:['de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de']\n"
     ]
    }
   ],
   "source": [
    "element = panx_ds_combined['de']['train'][0]\n",
    "print(panx_ds_combined['de']['train'].features)\n",
    "for key,value in element.items():\n",
    "    print(f\"{key}:{value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], id=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = panx_ds_combined['de']['train'].features['ner_tags'].feature\n",
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/raj/.cache/huggingface/datasets/xtreme/PAN-X.de/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-365871c98eb5223e.arrow\n",
      "Loading cached processed dataset at /home/raj/.cache/huggingface/datasets/xtreme/PAN-X.de/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-f321c19e5dd9c232.arrow\n",
      "Loading cached processed dataset at /home/raj/.cache/huggingface/datasets/xtreme/PAN-X.de/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-4453e3cf0a67f823.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs', 'ner_tags_str'],\n",
       "        num_rows: 12580\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs', 'ner_tags_str'],\n",
       "        num_rows: 6290\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs', 'ner_tags_str'],\n",
       "        num_rows: 6290\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_tag_names(batch):\n",
    "    return {'ner_tags_str' : [tags.int2str(idx) for idx in batch['ner_tags']]}\n",
    "\n",
    "panx_de = panx_ds_combined['de'].map(create_tag_names)\n",
    "panx_de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'I-LOC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'B-LOC',\n",
       " 'I-LOC',\n",
       " 'O']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panx_de['train'][0]['ner_tags_str']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>2.000</td>\n",
       "      <td>Einwohnern</td>\n",
       "      <td>an</td>\n",
       "      <td>der</td>\n",
       "      <td>Danziger</td>\n",
       "      <td>Bucht</td>\n",
       "      <td>in</td>\n",
       "      <td>der</td>\n",
       "      <td>polnischen</td>\n",
       "      <td>Woiwodschaft</td>\n",
       "      <td>Pommern</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tags</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0           1   2    3         4      5   6    7           8   \\\n",
       "Tokens  2.000  Einwohnern  an  der  Danziger  Bucht  in  der  polnischen   \n",
       "Tags        O           O   O    O     B-LOC  I-LOC   O    O       B-LOC   \n",
       "\n",
       "                  9        10 11  \n",
       "Tokens  Woiwodschaft  Pommern  .  \n",
       "Tags           B-LOC    I-LOC  O  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "de_example = panx_de[\"train\"][0]\n",
    "pd.DataFrame([de_example[\"tokens\"], de_example[\"ner_tags_str\"]],['Tokens', 'Tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOC</th>\n",
       "      <th>ORG</th>\n",
       "      <th>PER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>6186</td>\n",
       "      <td>5366</td>\n",
       "      <td>5810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation</th>\n",
       "      <td>3172</td>\n",
       "      <td>2683</td>\n",
       "      <td>2893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>3180</td>\n",
       "      <td>2573</td>\n",
       "      <td>3071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             LOC   ORG   PER\n",
       "train       6186  5366  5810\n",
       "validation  3172  2683  2893\n",
       "test        3180  2573  3071"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def get_ner_frequencies(panx_de):\n",
    "  split2freqs = defaultdict(Counter)\n",
    "  for split, dataset in panx_de.items():\n",
    "      for row in dataset[\"ner_tags_str\"]:\n",
    "          for tag in row:\n",
    "              if tag.startswith(\"B\"):\n",
    "                  tag_type = tag.split(\"-\")[1]\n",
    "                  split2freqs[split][tag_type] += 1\n",
    "  return split2freqs\n",
    "\n",
    "freqs = get_ner_frequencies(panx_de)\n",
    "\n",
    "pd.DataFrame.from_dict(freqs, orient=\"index\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a Custom model for Token Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from matplotlib import pyplot as plt\n",
    "from transformers import XLMRobertaConfig\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "from transformers.models.roberta.modeling_roberta import RobertaModel\n",
    "from transformers.models.roberta.modeling_roberta import RobertaPreTrainedModel\n",
    "\n",
    "class XLMRobertaForTokenClassification(RobertaPreTrainedModel):\n",
    "    config_class = XLMRobertaConfig\n",
    "    def __init__(self,config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.roberta = RobertaModel(config,add_pooling_layer=False)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size,config.num_labels)\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self,input_ids=None,attention_mask=None,token_type_ids=None, \n",
    "        labels=None, **kwargs):\n",
    "        outputs = self.roberta(input_ids, attention_mask=attention_mask,\n",
    "                        token_type_ids=token_type_ids, **kwargs)\n",
    "        # Apply classifier to encoder representation\n",
    "        sequence_output = self.dropout(outputs[0])\n",
    "        logits = self.classifier(sequence_output)\n",
    "        # Calculate losses\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "        # Return model output object\n",
    "        return TokenClassifierOutput(loss=loss, logits=logits, \n",
    "                                hidden_states=outputs.hidden_states, \n",
    "                                attentions=outputs.attentions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "index2tag = {idx: tag for idx, tag in enumerate(tags.names)}\n",
    "tag2index = {tag: idx for idx, tag in enumerate(tags.names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'O',\n",
       " 1: 'B-PER',\n",
       " 2: 'I-PER',\n",
       " 3: 'B-ORG',\n",
       " 4: 'I-ORG',\n",
       " 5: 'B-LOC',\n",
       " 6: 'I-LOC'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index2tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 0,\n",
       " 'B-PER': 1,\n",
       " 'I-PER': 2,\n",
       " 'B-ORG': 3,\n",
       " 'I-ORG': 4,\n",
       " 'B-LOC': 5,\n",
       " 'I-LOC': 6}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model_name = \"bert-base-cased\"\n",
    "xlmr_model_name = \"xlm-roberta-base\"\n",
    "\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(bert_model_name)\n",
    "xlmr_tokenizer = AutoTokenizer.from_pretrained(xlmr_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlmr_config = AutoConfig.from_pretrained(xlmr_model_name, \n",
    "                                         num_labels=tags.num_classes,\n",
    "                                         id2label=index2tag, label2id=tag2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XLMRobertaConfig {\n",
       "  \"_name_or_path\": \"xlm-roberta-base\",\n",
       "  \"architectures\": [\n",
       "    \"XLMRobertaForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"id2label\": {\n",
       "    \"0\": \"O\",\n",
       "    \"1\": \"B-PER\",\n",
       "    \"2\": \"I-PER\",\n",
       "    \"3\": \"B-ORG\",\n",
       "    \"4\": \"I-ORG\",\n",
       "    \"5\": \"B-LOC\",\n",
       "    \"6\": \"I-LOC\"\n",
       "  },\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"label2id\": {\n",
       "    \"B-LOC\": 5,\n",
       "    \"B-ORG\": 3,\n",
       "    \"B-PER\": 1,\n",
       "    \"I-LOC\": 6,\n",
       "    \"I-ORG\": 4,\n",
       "    \"I-PER\": 2,\n",
       "    \"O\": 0\n",
       "  },\n",
       "  \"layer_norm_eps\": 1e-05,\n",
       "  \"max_position_embeddings\": 514,\n",
       "  \"model_type\": \"xlm-roberta\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"output_past\": true,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.30.0\",\n",
       "  \"type_vocab_size\": 1,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 250002\n",
       "}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlmr_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForTokenClassification: ['roberta.pooler.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['roberta.embeddings.position_ids', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = 'cpu'\n",
    "\n",
    "xlmr_my_model = (XLMRobertaForTokenClassification\n",
    "              .from_pretrained(xlmr_model_name, config=xlmr_config)\n",
    "              .to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>', '▁World', '▁will', '▁be', '▁changed', '▁with', '▁AI', '</s>']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_string = 'World will be changed with AI'\n",
    "\n",
    "xlmr_token = xlmr_tokenizer(example_string).tokens()\n",
    "xlmr_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]', 'World', 'will', 'be', 'changed', 'with', 'AI', '[SEP]']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokens = bert_tokenizer(example_string).tokens()\n",
    "bert_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_text(text, tags, model, tokenizer):\n",
    "    \"\"\"\n",
    "    Function to tag text using a pretrained model and tokenizer.\n",
    "\n",
    "    Parameters:\n",
    "    text (str): Text to be tagged.\n",
    "    tags (Tags): An instance of the Tags class that maps class indices to names.\n",
    "    model (Model): Pretrained model for named entity recognition.\n",
    "    tokenizer (Tokenizer): Pretrained tokenizer corresponding to the model.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame containing the original tokens and their corresponding tags.\n",
    "    \"\"\"\n",
    "    # Tokenize the text, preserving special characters\n",
    "    tokens = tokenizer(text).tokens()\n",
    "\n",
    "    # Encode the tokens into their corresponding IDs\n",
    "    # 'return_tensors=\"pt\"' indicates that we want PyTorch tensors\n",
    "    # '.to(device)' sends the tensors to the GPU if one is available\n",
    "    input_ids = tokenizer(text, return_tensors=\"pt\").input_ids.to(device)\n",
    "\n",
    "    # Print the input IDs for debugging purposes\n",
    "    print('input_ids ', input_ids)\n",
    "\n",
    "    # Get the model's predictions as a distribution over possible classes\n",
    "    # Each token is associated with a probability distribution over the 7 possible NER tags\n",
    "    outputs = model(input_ids)[0]\n",
    "    print(f\"Shape of outputs: {outputs.shape}\")\n",
    "\n",
    "    # Take the argmax over the tag dimension to get the most likely class for each token\n",
    "    predictions = torch.argmax(outputs, dim=2)\n",
    "    print('predictions ', predictions)\n",
    "\n",
    "    # Convert the predictions from class indices to class names using the 'tags' object\n",
    "    # '.cpu().numpy()' moves the tensor from GPU to CPU and converts it to a NumPy array\n",
    "    preds = [tags.names[p] for p in predictions[0].cpu().numpy()]\n",
    "\n",
    "    # Return the tokens and their corresponding tags as a DataFrame\n",
    "    return pd.DataFrame([tokens, preds], index=[\"Tokens\", \"Tags\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], id=None)\n",
      "XLMRobertaTokenizerFast(name_or_path='xlm-roberta-base', vocab_size=250002, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False)}, clean_up_tokenization_spaces=True)\n"
     ]
    }
   ],
   "source": [
    "print(tags)\n",
    "print(xlmr_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids  tensor([[    0,  6661,  1221,   186, 98816,   678, 38730,     2]],\n",
      "       device='cuda:0')\n",
      "Shape of outputs: torch.Size([1, 8, 7])\n",
      "predictions  tensor([[5, 5, 5, 5, 5, 5, 5, 5]], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁World</td>\n",
       "      <td>▁will</td>\n",
       "      <td>▁be</td>\n",
       "      <td>▁changed</td>\n",
       "      <td>▁with</td>\n",
       "      <td>▁AI</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tags</th>\n",
       "      <td>B-LOC</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>B-LOC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0       1      2      3         4      5      6      7\n",
       "Tokens    <s>  ▁World  ▁will    ▁be  ▁changed  ▁with    ▁AI   </s>\n",
       "Tags    B-LOC   B-LOC  B-LOC  B-LOC     B-LOC  B-LOC  B-LOC  B-LOC"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_text(example_string, tags, xlmr_my_model, xlmr_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "words, labels = de_example[\"tokens\"], de_example[\"ner_tags\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['2.000',\n",
       "  'Einwohnern',\n",
       "  'an',\n",
       "  'der',\n",
       "  'Danziger',\n",
       "  'Bucht',\n",
       "  'in',\n",
       "  'der',\n",
       "  'polnischen',\n",
       "  'Woiwodschaft',\n",
       "  'Pommern',\n",
       "  '.'],\n",
       " [0, 0, 0, 0, 5, 6, 0, 0, 5, 5, 6, 0])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " '▁2.000',\n",
       " '▁Einwohner',\n",
       " 'n',\n",
       " '▁an',\n",
       " '▁der',\n",
       " '▁Dan',\n",
       " 'zi',\n",
       " 'ger',\n",
       " '▁Buch',\n",
       " 't',\n",
       " '▁in',\n",
       " '▁der',\n",
       " '▁polni',\n",
       " 'schen',\n",
       " '▁Wo',\n",
       " 'i',\n",
       " 'wod',\n",
       " 'schaft',\n",
       " '▁Po',\n",
       " 'mmer',\n",
       " 'n',\n",
       " '▁',\n",
       " '.',\n",
       " '</s>']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_input = xlmr_tokenizer(de_example[\"tokens\"], is_split_into_words=True)\n",
    "\n",
    "tokens = xlmr_tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_ids  [None, 0, 1, 1, 2, 3, 4, 4, 4, 5, 5, 6, 7, 8, 8, 9, 9, 9, 9, 10, 10, 10, 11, 11, None]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁2.000</td>\n",
       "      <td>▁Einwohner</td>\n",
       "      <td>n</td>\n",
       "      <td>▁an</td>\n",
       "      <td>▁der</td>\n",
       "      <td>▁Dan</td>\n",
       "      <td>zi</td>\n",
       "      <td>ger</td>\n",
       "      <td>▁Buch</td>\n",
       "      <td>...</td>\n",
       "      <td>▁Wo</td>\n",
       "      <td>i</td>\n",
       "      <td>wod</td>\n",
       "      <td>schaft</td>\n",
       "      <td>▁Po</td>\n",
       "      <td>mmer</td>\n",
       "      <td>n</td>\n",
       "      <td>▁</td>\n",
       "      <td>.</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word IDs</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0       1           2  3    4     5     6   7    8      9   ...  \\\n",
       "Tokens     <s>  ▁2.000  ▁Einwohner  n  ▁an  ▁der  ▁Dan  zi  ger  ▁Buch  ...   \n",
       "Word IDs  None       0           1  1    2     3     4   4    4      5  ...   \n",
       "\n",
       "           15 16   17      18   19    20  21  22  23    24  \n",
       "Tokens    ▁Wo  i  wod  schaft  ▁Po  mmer   n   ▁   .  </s>  \n",
       "Word IDs    9  9    9       9   10    10  10  11  11  None  \n",
       "\n",
       "[2 rows x 25 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_ids = tokenized_input.word_ids()\n",
    "print('word_ids ', word_ids)\n",
    "\n",
    "pd.DataFrame([tokens, word_ids], index=[\"Tokens\", \"Word IDs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_ids  [-100, 0, 0, -100, 0, 0, 5, -100, -100, 6, -100, 0, 0, 5, -100, 5, -100, -100, -100, 6, -100, -100, 0, -100, -100]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁2.000</td>\n",
       "      <td>▁Einwohner</td>\n",
       "      <td>n</td>\n",
       "      <td>▁an</td>\n",
       "      <td>▁der</td>\n",
       "      <td>▁Dan</td>\n",
       "      <td>zi</td>\n",
       "      <td>ger</td>\n",
       "      <td>▁Buch</td>\n",
       "      <td>...</td>\n",
       "      <td>▁Wo</td>\n",
       "      <td>i</td>\n",
       "      <td>wod</td>\n",
       "      <td>schaft</td>\n",
       "      <td>▁Po</td>\n",
       "      <td>mmer</td>\n",
       "      <td>n</td>\n",
       "      <td>▁</td>\n",
       "      <td>.</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word IDs</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label IDs</th>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>6</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Labels</th>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>...</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0       1           2     3    4     5      6     7     8   \\\n",
       "Tokens      <s>  ▁2.000  ▁Einwohner     n  ▁an  ▁der   ▁Dan    zi   ger   \n",
       "Word IDs   None       0           1     1    2     3      4     4     4   \n",
       "Label IDs  -100       0           0  -100    0     0      5  -100  -100   \n",
       "Labels      IGN       O           O   IGN    O     O  B-LOC   IGN   IGN   \n",
       "\n",
       "              9   ...     15    16    17      18     19    20    21  22    23  \\\n",
       "Tokens     ▁Buch  ...    ▁Wo     i   wod  schaft    ▁Po  mmer     n   ▁     .   \n",
       "Word IDs       5  ...      9     9     9       9     10    10    10  11    11   \n",
       "Label IDs      6  ...      5  -100  -100    -100      6  -100  -100   0  -100   \n",
       "Labels     I-LOC  ...  B-LOC   IGN   IGN     IGN  I-LOC   IGN   IGN   O   IGN   \n",
       "\n",
       "             24  \n",
       "Tokens     </s>  \n",
       "Word IDs   None  \n",
       "Label IDs  -100  \n",
       "Labels      IGN  \n",
       "\n",
       "[4 rows x 25 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previous_word_idx = None\n",
    "label_ids = []\n",
    "\n",
    "for word_idx in word_ids:\n",
    "    if word_idx is None or word_idx == previous_word_idx:\n",
    "        label_ids.append(-100)\n",
    "    elif word_idx != previous_word_idx:\n",
    "        label_ids.append(labels[word_idx])\n",
    "    # And then update previous_word_idx\n",
    "    # to be current word\n",
    "    previous_word_idx = word_idx\n",
    "\n",
    "print('label_ids ', label_ids)\n",
    "    \n",
    "labels = [index2tag[l] if l != -100 else \"IGN\" for l in label_ids]\n",
    "index = [\"Tokens\", \"Word IDs\", \"Label IDs\", \"Labels\"]\n",
    "\n",
    "pd.DataFrame([tokens, word_ids, label_ids, labels], index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_mask_modify_labels(examples):\n",
    "    \"\"\"\n",
    "    Function to tokenize the input text, mask certain tokens, and adjust the labels accordingly.\n",
    "\n",
    "    Parameters:\n",
    "    examples (dict): A dictionary containing the input text and labels. The input text (\"tokens\") is a list of words, \n",
    "                     and the labels (\"ner_tags\") are a corresponding list of NER tags.\n",
    "\n",
    "    Returns:\n",
    "    tokenized_inputs (dict): A dictionary containing the tokenized input text and modified labels. The tokenized input \n",
    "                             text is a list of token IDs, and the modified labels are a corresponding list of NER tags, \n",
    "                             with -100 indicating masked tokens.\n",
    "    \"\"\"\n",
    "    tokenized_inputs = xlmr_tokenizer(examples[\"tokens\"], truncation=True, \n",
    "                                      is_split_into_words=True)\n",
    "    labels = []\n",
    "    for idx, label in enumerate(examples[\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=idx)\n",
    "        # word_ids() => Return a list mapping the tokens\n",
    "        # to their actual word in the initial sentence.\n",
    "        # It Returns a list indicating the word corresponding to each token. \n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        # Special tokens like `<s>` and `<\\s>` are mapped to None. \n",
    "        # Set –100 as the label for these special tokens and\n",
    "        # the subwords we wish to mask during training:\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None or word_idx == previous_word_idx:\n",
    "                label_ids.append(-100)\n",
    "            else:\n",
    "                label_ids.append(label[word_idx])\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_panx_dataset(corpus):\n",
    "    return corpus.map(tokenize_mask_modify_labels, batched=True, \n",
    "                      remove_columns=['langs', 'ner_tags', 'tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/raj/.cache/huggingface/datasets/xtreme/PAN-X.de/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-ee43ed1891039798.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae366768da15483a97909a788e53d349",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6290 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/raj/.cache/huggingface/datasets/xtreme/PAN-X.de/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-3b09521252c88e6d.arrow\n"
     ]
    }
   ],
   "source": [
    "panx_de_encoded = encode_panx_dataset(panx_ds_combined[\"de\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 12580\n",
       "})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panx_de_encoded[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        MISC       0.00      0.00      0.00         1\n",
      "         PER       0.50      1.00      0.67         1\n",
      "\n",
      "   micro avg       0.33      0.50      0.40         2\n",
      "   macro avg       0.25      0.50      0.33         2\n",
      "weighted avg       0.25      0.50      0.33         2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import classification_report\n",
    "\n",
    "y_true = [[\"O\", \"O\", \"O\", \"B-MISC\", \"I-MISC\", \"I-MISC\", \"O\"],\n",
    "          [\"B-PER\", \"I-PER\", \"O\"],['O']]\n",
    "y_pred = [[\"O\", \"O\", \"B-MISC\", \"I-MISC\", \"I-MISC\", \"I-MISC\", \"O\"],\n",
    "          [\"B-PER\", \"I-PER\", \"O\"],['I-PER']]\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_list_for_compute_metrics(predictions, label_ids):\n",
    "    \"\"\"\n",
    "    Function to generate prediction and true labels lists for computing metrics.\n",
    "\n",
    "    Parameters:\n",
    "    predictions (np.ndarray): A 2D numpy array containing the predicted label IDs for each token in each example.\n",
    "    label_ids (np.ndarray): A 2D numpy array containing the true label IDs for each token in each example.\n",
    "\n",
    "    Returns:\n",
    "    preds_labels_list (list): A list of lists, where each sublist contains the predicted labels for each token in an example.\n",
    "    true_labels_list (list): A list of lists, where each sublist contains the true labels for each token in an example.\n",
    "    \"\"\"\n",
    "    # Get the predicted labels by taking the argmax over the second dimension of the predictions array\n",
    "    preds = np.argmax(predictions, axis=2)\n",
    "    batch_size, seq_len = preds.shape\n",
    "    preds_labels_list, true_labels_list = [], []\n",
    "\n",
    "    # Iterate over each example in the batch\n",
    "    for batch_idx in range(batch_size):\n",
    "        example_labels, example_preds = [], []\n",
    "        # Iterate over each token in the example\n",
    "        for seq_idx in range(seq_len):\n",
    "            # Ignore tokens with label ID = -100 (these are special tokens or subwords that we masked during training)\n",
    "            if label_ids[batch_idx, seq_idx] != -100:\n",
    "                # Append the predicted and true labels for the token to the lists for the current example\n",
    "                example_preds.append(index2tag[preds[batch_idx][seq_idx]])\n",
    "                example_labels.append(index2tag[label_ids[batch_idx][seq_idx]])\n",
    "        # Append the lists for the current example to the main lists\n",
    "        preds_labels_list.append(example_preds)\n",
    "        true_labels_list.append(example_labels)\n",
    "\n",
    "    # Return the lists of predicted and true labels\n",
    "    return preds_labels_list, true_labels_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fine-Tuning XLM-RoBERTa**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 3\n",
    "batch_size = 16\n",
    "logging_steps = len(panx_de_encoded[\"train\"]) // batch_size\n",
    "model_name = f\"{xlmr_model_name}-finetuned-panx-de\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_name, log_level=\"error\", num_train_epochs=num_epochs, \n",
    "    per_device_train_batch_size=batch_size, \n",
    "    per_device_eval_batch_size=batch_size, evaluation_strategy=\"epoch\", \n",
    "    save_steps=1e6, weight_decay=0.01, disable_tqdm=False, \n",
    "    logging_steps=logging_steps, push_to_hub=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import f1_score\n",
    "from transformers import EvalPrediction\n",
    "\n",
    "''' compute_metrics (Callable[[EvalPrediction], Dict], optional) – The function that will be used to compute metrics at evaluation. Must take a EvalPrediction and return a dictionary string to metric values. \n",
    "https://huggingface.co/transformers/v4.2.2/main_classes/trainer.html#id1\n",
    "'''\n",
    "def compute_metrics(eval_pred: EvalPrediction):\n",
    "    \"\"\"\n",
    "    Computes the F1 score metric for the model evaluation.\n",
    "\n",
    "    Args:\n",
    "        eval_pred (EvalPrediction): Object containing the model predictions and labels.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing the computed F1 score.\n",
    "\n",
    "    \"\"\"\n",
    "    # print('eval_pred ', eval_pred)\n",
    "    print('eval_pred.predictions ', eval_pred.predictions)\n",
    "    # Output =>  <transformers.trainer_utils.EvalPrediction object\n",
    "    y_pred, y_true = generate_list_for_compute_metrics(eval_pred.predictions, \n",
    "                                       eval_pred.label_ids)\n",
    "    return {\"f1\": f1_score(y_true, y_pred)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(xlmr_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init():\n",
    "    return (XLMRobertaForTokenClassification\n",
    "            .from_pretrained(xlmr_model_name, config=xlmr_config)\n",
    "            .to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(model_init=model_init, args=training_args, \n",
    "                  data_collator=data_collator, compute_metrics=compute_metrics,\n",
    "                  train_dataset=panx_de_encoded[\"train\"],\n",
    "                  eval_dataset=panx_de_encoded[\"validation\"], \n",
    "                  tokenizer=xlmr_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/.conda/envs/raj/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrajgothi6\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/raj/NLP-and-Speech-Hugging-Face/wandb/run-20230627_053521-eyxamz5w</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rajgothi6/huggingface/runs/eyxamz5w' target=\"_blank\">skilled-donkey-8</a></strong> to <a href='https://wandb.ai/rajgothi6/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rajgothi6/huggingface' target=\"_blank\">https://wandb.ai/rajgothi6/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rajgothi6/huggingface/runs/eyxamz5w' target=\"_blank\">https://wandb.ai/rajgothi6/huggingface/runs/eyxamz5w</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/.conda/envs/raj/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1182' max='1182' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1182/1182 07:53, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.180434</td>\n",
       "      <td>0.803022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.204700</td>\n",
       "      <td>0.142484</td>\n",
       "      <td>0.843583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.204700</td>\n",
       "      <td>0.136383</td>\n",
       "      <td>0.858620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_pred.predictions  [[[-4.1403687e-01 -3.9400619e-01 -4.3837306e-01 ...  1.7881421e+00\n",
      "    1.3448036e-01 -1.4259745e-01]\n",
      "  [-6.1203045e-01  1.5144343e+00 -3.4386358e+00 ... -8.8810199e-01\n",
      "    2.9373279e+00 -2.8782537e+00]\n",
      "  [-9.6393102e-01 -1.6809767e+00 -1.5021679e+00 ...  3.4807677e+00\n",
      "   -5.2823406e-01  5.2391118e-01]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[ 3.1438997e-01 -5.0747150e-01 -2.0921549e-02 ...  3.6626923e-01\n",
      "    5.2854884e-01  2.4537130e-01]\n",
      "  [ 7.8270316e+00 -2.0020046e+00 -2.1916299e+00 ... -6.5658182e-01\n",
      "   -1.0020458e+00 -1.8330480e+00]\n",
      "  [ 7.3678455e+00 -2.0044680e+00 -2.1036887e+00 ... -3.0562097e-01\n",
      "   -1.0294210e+00 -1.1397626e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[ 2.7758727e+00 -9.4731426e-01 -2.0651326e+00 ... -4.9323335e-01\n",
      "    1.0872220e+00 -1.0423164e+00]\n",
      "  [ 7.9462547e+00 -2.1356757e+00 -2.1017985e+00 ... -6.8049598e-01\n",
      "   -9.6992296e-01 -1.4223517e+00]\n",
      "  [ 8.2977228e+00 -2.5280876e+00 -1.9149573e+00 ... -2.9793391e-01\n",
      "   -1.6760963e+00 -1.2933587e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 3.0189002e+00 -1.2654309e+00 -1.9247679e+00 ... -6.8292898e-01\n",
      "    1.3303981e+00 -1.2464335e+00]\n",
      "  [ 8.0565701e+00 -2.2910383e+00 -2.3893619e+00 ... -4.5019728e-01\n",
      "   -1.0457457e+00 -1.5829500e+00]\n",
      "  [ 8.2289686e+00 -2.3782470e+00 -2.2763267e+00 ... -2.8936839e-01\n",
      "   -1.1828922e+00 -1.6281800e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[ 2.2980618e+00 -7.8473389e-01 -2.0948064e+00 ...  1.0354761e-02\n",
      "    8.2627207e-01 -1.2610663e+00]\n",
      "  [ 7.7587852e+00 -2.2645416e+00 -2.5194170e+00 ... -3.7961003e-01\n",
      "   -1.0885736e+00 -1.8018301e+00]\n",
      "  [ 6.0451169e+00 -1.8683898e+00 -2.5837784e+00 ...  3.3990543e-02\n",
      "   -8.2927495e-01 -1.8230276e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[ 1.3349799e+00 -6.1453986e-01 -1.4925725e+00 ... -9.6891648e-01\n",
      "    1.3969504e+00 -7.1996796e-01]\n",
      "  [ 7.9561882e+00 -2.0422759e+00 -2.2806392e+00 ... -8.2244605e-01\n",
      "   -9.4998527e-01 -1.7695256e+00]\n",
      "  [ 7.8247976e+00 -1.9985523e+00 -2.1903071e+00 ... -7.9115194e-01\n",
      "   -9.5233047e-01 -1.8634971e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]]\n",
      "eval_pred.predictions  [[[-1.2142303e-01  4.2900580e-01  6.1704522e-01 ...  1.9935572e+00\n",
      "   -2.0211606e+00 -1.4454829e+00]\n",
      "  [-4.6671072e-01  2.7952368e+00 -2.3010149e+00 ... -1.2696588e+00\n",
      "    5.2142817e-01 -3.6245220e+00]\n",
      "  [-8.9655113e-01 -2.5176495e-01  8.9585567e-01 ...  3.2375326e+00\n",
      "   -2.7798691e+00 -1.6044590e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[ 1.3329962e+00 -2.2969909e-01  2.4031503e-01 ...  1.0187311e-01\n",
      "   -9.7465879e-01 -4.3218878e-01]\n",
      "  [ 8.0043859e+00 -1.7402704e+00 -1.7483599e+00 ... -1.2208178e+00\n",
      "   -1.4819016e+00 -2.1077325e+00]\n",
      "  [ 7.2842045e+00 -1.6850669e+00 -1.8623588e+00 ... -9.0339565e-01\n",
      "   -1.4372543e+00 -1.5004570e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[ 3.5679646e+00 -9.0271705e-01 -1.6607225e+00 ... -1.1000705e+00\n",
      "    5.8786217e-02 -1.6556737e+00]\n",
      "  [ 8.4812250e+00 -1.9352106e+00 -1.6971122e+00 ... -1.2076904e+00\n",
      "   -1.5851262e+00 -1.7511226e+00]\n",
      "  [ 8.6344004e+00 -2.4401972e+00 -1.4019985e+00 ... -6.8680787e-01\n",
      "   -2.2432828e+00 -1.2084117e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 4.2050290e+00 -1.2393320e+00 -1.8781778e+00 ... -1.5167968e+00\n",
      "    1.9345760e-01 -1.7222550e+00]\n",
      "  [ 8.7632360e+00 -2.2926071e+00 -1.7937502e+00 ... -9.4082731e-01\n",
      "   -1.7778977e+00 -1.7194242e+00]\n",
      "  [ 8.8335352e+00 -2.3541901e+00 -1.7883759e+00 ... -7.7619517e-01\n",
      "   -1.8842140e+00 -1.6716278e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[ 3.0828574e+00 -7.5009441e-01 -1.5612549e+00 ... -6.2627214e-01\n",
      "   -6.2629186e-02 -1.9198349e+00]\n",
      "  [ 8.2636242e+00 -1.8509543e+00 -1.9518542e+00 ... -7.8944910e-01\n",
      "   -1.8152813e+00 -2.0710969e+00]\n",
      "  [ 6.4532628e+00 -1.3793280e+00 -2.0330551e+00 ... -2.2919320e-01\n",
      "   -1.4671575e+00 -2.3347976e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[ 1.2379431e+00 -5.8657908e-01 -1.1016345e+00 ... -4.8665631e-01\n",
      "   -1.4456695e-01 -2.0006597e-01]\n",
      "  [ 8.5917988e+00 -2.0861349e+00 -1.9235188e+00 ... -9.6473491e-01\n",
      "   -1.7288076e+00 -1.8948293e+00]\n",
      "  [ 8.5249729e+00 -2.0541420e+00 -1.8964902e+00 ... -9.3378770e-01\n",
      "   -1.6343926e+00 -2.0095003e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]]\n",
      "eval_pred.predictions  [[[-9.1003114e-01 -5.4299887e-02  6.1058420e-01 ...  3.4409151e+00\n",
      "   -1.7418239e+00 -1.3875077e+00]\n",
      "  [-1.3034490e+00  2.2863870e+00 -2.9026532e+00 ... -1.1998141e+00\n",
      "    6.6730738e-01 -3.7623971e+00]\n",
      "  [-1.6369596e+00 -1.2530290e+00  5.8234155e-01 ...  4.7710752e+00\n",
      "   -2.8779860e+00 -1.4621029e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[ 5.3283173e-01 -3.9302757e-01  4.9810126e-01 ...  1.1704993e+00\n",
      "   -1.2111791e+00 -9.8708965e-02]\n",
      "  [ 8.4725285e+00 -1.7848206e+00 -1.9621264e+00 ... -1.3873925e+00\n",
      "   -1.2375113e+00 -2.2074690e+00]\n",
      "  [ 8.0641336e+00 -2.0186989e+00 -1.9946891e+00 ... -1.0295781e+00\n",
      "   -1.2802979e+00 -1.5406051e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[ 3.4073539e+00 -1.0147625e+00 -1.8652414e+00 ... -9.0242231e-01\n",
      "   -9.4557829e-02 -1.3654639e+00]\n",
      "  [ 8.5682974e+00 -1.8926420e+00 -1.7811694e+00 ... -1.3760109e+00\n",
      "   -1.2227085e+00 -1.8579904e+00]\n",
      "  [ 9.0413675e+00 -2.5025041e+00 -1.5409708e+00 ... -8.2923776e-01\n",
      "   -1.9916636e+00 -1.3427035e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 4.0632796e+00 -1.2376887e+00 -2.0316532e+00 ... -1.4227755e+00\n",
      "    9.2286967e-02 -1.4922972e+00]\n",
      "  [ 8.9022923e+00 -2.2298315e+00 -1.9376689e+00 ... -1.1523641e+00\n",
      "   -1.3990468e+00 -1.9310338e+00]\n",
      "  [ 9.0385990e+00 -2.2715917e+00 -1.9407371e+00 ... -1.0206033e+00\n",
      "   -1.4247946e+00 -1.8978853e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[ 3.0885479e+00 -1.0434924e+00 -1.8381916e+00 ... -3.5039443e-01\n",
      "   -7.1041726e-02 -1.6534302e+00]\n",
      "  [ 8.3325472e+00 -1.8877469e+00 -2.0082967e+00 ... -9.8846149e-01\n",
      "   -1.3820283e+00 -2.3529410e+00]\n",
      "  [ 6.8239503e+00 -1.6773783e+00 -2.1886950e+00 ... -3.6113319e-01\n",
      "   -1.2594656e+00 -2.3389294e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[ 1.1945779e+00 -5.8349818e-01 -1.0274640e+00 ... -3.8464892e-01\n",
      "   -2.3605043e-01 -1.5785587e-01]\n",
      "  [ 8.7467384e+00 -2.2226446e+00 -2.0188789e+00 ... -1.3213524e+00\n",
      "   -1.5422733e+00 -1.8406005e+00]\n",
      "  [ 8.7542944e+00 -2.2381151e+00 -1.9362183e+00 ... -1.2893759e+00\n",
      "   -1.5257940e+00 -1.8627346e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1182, training_loss=0.16586437967626375, metrics={'train_runtime': 483.129, 'train_samples_per_second': 78.116, 'train_steps_per_second': 2.447, 'total_flos': 914722893139440.0, 'train_loss': 0.16586437967626375, 'epoch': 3.0})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.180434</td>\n",
       "      <td>0.803022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.2047</td>\n",
       "      <td>0.142484</td>\n",
       "      <td>0.843583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.2047</td>\n",
       "      <td>0.136383</td>\n",
       "      <td>0.858620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Epoch  Training Loss  Validation Loss        F1\n",
       "0      1            NaN         0.180434  0.803022\n",
       "1      2         0.2047         0.142484  0.843583\n",
       "3      3         0.2047         0.136383  0.858620"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(trainer.state.log_history)[['epoch','loss' ,'eval_loss', 'eval_f1']]\n",
    "df = df.rename(columns={\"epoch\":\"Epoch\",\"loss\": \"Training Loss\", \"eval_loss\": \"Validation Loss\", \"eval_f1\":\"F1\"})\n",
    "df['Epoch'] = df[\"Epoch\"].apply(lambda x: round(x))\n",
    "df['Training Loss'] = df[\"Training Loss\"].ffill()\n",
    "df[['Validation Loss', 'F1']] = df[['Validation Loss', 'F1']].bfill().ffill()\n",
    "df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids  tensor([[     0,    622,  35473,   4932,   1256,  22667,  47582, 105173,     23,\n",
      "          37061,      2]], device='cuda:0')\n",
      "Shape of outputs: torch.Size([1, 11, 7])\n",
      "predictions  tensor([[0, 0, 3, 4, 0, 0, 0, 0, 0, 5, 0]], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁Die</td>\n",
       "      <td>▁Deutsche</td>\n",
       "      <td>▁Bank</td>\n",
       "      <td>▁hat</td>\n",
       "      <td>▁ihren</td>\n",
       "      <td>▁Haupt</td>\n",
       "      <td>sitz</td>\n",
       "      <td>▁in</td>\n",
       "      <td>▁Frankfurt</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tags</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0     1          2      3     4       5       6     7    8   \\\n",
       "Tokens  <s>  ▁Die  ▁Deutsche  ▁Bank  ▁hat  ▁ihren  ▁Haupt  sitz  ▁in   \n",
       "Tags      O     O      B-ORG  I-ORG     O       O       O     O    O   \n",
       "\n",
       "                9     10  \n",
       "Tokens  ▁Frankfurt  </s>  \n",
       "Tags         B-LOC     O  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# text_de = \"Jeff Dean ist ein Informatiker bei Google in Kalifornien\"\n",
    "\n",
    "# The english of the below random German sentence is \n",
    "# Deutsche Bank is headquartered in Frankfurt\n",
    "\n",
    "text_de = \"Die Deutsche Bank hat ihren Hauptsitz in Frankfurt\"\n",
    "tag_text(text_de, tags, trainer.model, xlmr_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 6290\n",
       "})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_set_batch = panx_de_encoded[\"validation\"]\n",
    "valid_set_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\n",
       " 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None),\n",
       " 'labels': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None)}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_set_batch.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_set_batch.features[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_set_batch.features[\"attention_mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import cross_entropy\n",
    "\n",
    "def get_forward_loss_and_label(batch):\n",
    "    \"\"\"\n",
    "    Function to compute the loss and the predicted label for a given batch.\n",
    "\n",
    "    Parameters:\n",
    "    batch (dict): A batch of input data, containing the input_ids, attention_mask, and labels.\n",
    "\n",
    "    Returns:\n",
    "    results (dict): A dictionary containing the loss and predicted labels.\n",
    "    \"\"\"\n",
    "    # Convert dict of lists to list of dicts suitable for data collator\n",
    "    features = [dict(zip(batch, t)) for t in zip(*batch.values())]\n",
    "    # Pad inputs and labels and put all tensors on device\n",
    "    batch = data_collator(features)\n",
    "    input_ids = batch[\"input_ids\"].to(device)\n",
    "    attention_mask = batch[\"attention_mask\"].to(device)\n",
    "    labels = batch[\"labels\"].to(device)\n",
    "    with torch.no_grad():\n",
    "        # Pass data through model  \n",
    "        # trainer.model(PreTrainedModel or torch.nn.Module, optional)\n",
    "        # This is the model to train, evaluate or use for predictions.\n",
    "        output = trainer.model(input_ids, attention_mask)\n",
    "        # Logit.size: [batch_size, sequence_length, classes]\n",
    "        # Predict class with largest logit value on classes axis\n",
    "        predicted_label = torch.argmax(output.logits, axis=-1).cpu().numpy()\n",
    "    # Calculate loss per token after flattening batch dimension with view\n",
    "    loss = cross_entropy(output.logits.view(-1, 7), \n",
    "                         labels.view(-1), reduction=\"none\")\n",
    "    # Unflatten batch dimension and convert to numpy array\n",
    "    loss = loss.view(len(input_ids), -1).cpu().numpy()\n",
    "\n",
    "    return {\"loss\":loss, \"predicted_label\": predicted_label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function get_forward_loss_and_label at 0x7f6601f6bc40> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
      "Loading cached processed dataset at /home/raj/.cache/huggingface/datasets/xtreme/PAN-X.de/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-1c80317fa3b1799d.arrow\n"
     ]
    }
   ],
   "source": [
    "valid_set_with_loss = valid_set_batch.map(get_forward_loss_and_label, batched=True, batch_size=32)\n",
    "\n",
    "df = valid_set_with_loss.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>labels</th>\n",
       "      <th>loss</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 10699, 11, 15, 16104, 1388, 2]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[-100, 3, -100, 4, 4, 4, -100]</td>\n",
       "      <td>[0.0, 0.09230041, 0.0, 0.06614939, 0.037760213...</td>\n",
       "      <td>[0, 3, 4, 4, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, 56530, 25216, 30121, 152385, 19229, 83982,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[-100, 0, -100, -100, -100, -100, 3, -100, -10...</td>\n",
       "      <td>[0.0, 0.0006270826, 0.0, 0.0, 0.0, 0.0, 0.3244...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 3, 4, 4, 4, 4, 4, 4, 4, 4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 159093, 165, 38506, 122, 153080, 29088, 57...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[-100, 0, 0, 0, 0, 3, -100, -100, 0, -100, 0, ...</td>\n",
       "      <td>[0.0, 0.00037853705, 0.00028189024, 0.00029488...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0, 16459, 242, 5106, 6, 198715, 5106, 242, 2]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[-100, 0, 0, 0, 5, -100, 0, 0, -100]</td>\n",
       "      <td>[0.0, 0.00043990472, 0.00038902345, 0.00048065...</td>\n",
       "      <td>[0, 0, 0, 0, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0, 11022, 2315, 7418, 1079, 8186, 57242, 97, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[-100, 0, 0, 0, 0, 0, 0, 0, -100, 0, 0, 0, 3, ...</td>\n",
       "      <td>[0.0, 0.0003533931, 0.00029845553, 0.000334326...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6285</th>\n",
       "      <td>[0, 10333, 599, 7418, 4180, 72, 3700, 542, 900...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[-100, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 0, 0, -10...</td>\n",
       "      <td>[0.0, 0.00027235615, 0.00025388357, 0.00031370...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6286</th>\n",
       "      <td>[0, 15497, 7, 91243, 15, 23924, 96220, 1388, 2]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[-100, 5, -100, -100, 6, 6, 6, 6, -100]</td>\n",
       "      <td>[0.0, 0.026120104, 0.0, 0.0, 0.028340477, 0.02...</td>\n",
       "      <td>[6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6287</th>\n",
       "      <td>[0, 1858, 566, 12241, 729, 4598, 89841, 68125,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[-100, 0, 0, 0, 0, -100, 0, -100, -100, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.00036221143, 0.0002952378, 0.000558458...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6288</th>\n",
       "      <td>[0, 132005, 11399, 7, 84974, 168, 34525, 84247...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[-100, 0, 0, -100, 0, 0, 5, 6, 0, 0, -100, -100]</td>\n",
       "      <td>[0.0, 0.00060361286, 0.0047984445, 0.0, 0.0003...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6289</th>\n",
       "      <td>[0, 242, 5106, 223660, 5106, 242, 2]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[-100, 0, 0, 1, 0, 0, -100]</td>\n",
       "      <td>[0.0, 0.00045896962, 0.00050114945, 5.0468183,...</td>\n",
       "      <td>[0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6290 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              input_ids  \\\n",
       "0                    [0, 10699, 11, 15, 16104, 1388, 2]   \n",
       "1     [0, 56530, 25216, 30121, 152385, 19229, 83982,...   \n",
       "2     [0, 159093, 165, 38506, 122, 153080, 29088, 57...   \n",
       "3        [0, 16459, 242, 5106, 6, 198715, 5106, 242, 2]   \n",
       "4     [0, 11022, 2315, 7418, 1079, 8186, 57242, 97, ...   \n",
       "...                                                 ...   \n",
       "6285  [0, 10333, 599, 7418, 4180, 72, 3700, 542, 900...   \n",
       "6286    [0, 15497, 7, 91243, 15, 23924, 96220, 1388, 2]   \n",
       "6287  [0, 1858, 566, 12241, 729, 4598, 89841, 68125,...   \n",
       "6288  [0, 132005, 11399, 7, 84974, 168, 34525, 84247...   \n",
       "6289               [0, 242, 5106, 223660, 5106, 242, 2]   \n",
       "\n",
       "                                         attention_mask  \\\n",
       "0                                 [1, 1, 1, 1, 1, 1, 1]   \n",
       "1     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2            [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]   \n",
       "3                           [1, 1, 1, 1, 1, 1, 1, 1, 1]   \n",
       "4     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "...                                                 ...   \n",
       "6285  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "6286                        [1, 1, 1, 1, 1, 1, 1, 1, 1]   \n",
       "6287  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "6288               [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]   \n",
       "6289                              [1, 1, 1, 1, 1, 1, 1]   \n",
       "\n",
       "                                                 labels  \\\n",
       "0                        [-100, 3, -100, 4, 4, 4, -100]   \n",
       "1     [-100, 0, -100, -100, -100, -100, 3, -100, -10...   \n",
       "2     [-100, 0, 0, 0, 0, 3, -100, -100, 0, -100, 0, ...   \n",
       "3                  [-100, 0, 0, 0, 5, -100, 0, 0, -100]   \n",
       "4     [-100, 0, 0, 0, 0, 0, 0, 0, -100, 0, 0, 0, 3, ...   \n",
       "...                                                 ...   \n",
       "6285  [-100, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 0, 0, -10...   \n",
       "6286            [-100, 5, -100, -100, 6, 6, 6, 6, -100]   \n",
       "6287  [-100, 0, 0, 0, 0, -100, 0, -100, -100, 0, 0, ...   \n",
       "6288   [-100, 0, 0, -100, 0, 0, 5, 6, 0, 0, -100, -100]   \n",
       "6289                        [-100, 0, 0, 1, 0, 0, -100]   \n",
       "\n",
       "                                                   loss  \\\n",
       "0     [0.0, 0.09230041, 0.0, 0.06614939, 0.037760213...   \n",
       "1     [0.0, 0.0006270826, 0.0, 0.0, 0.0, 0.0, 0.3244...   \n",
       "2     [0.0, 0.00037853705, 0.00028189024, 0.00029488...   \n",
       "3     [0.0, 0.00043990472, 0.00038902345, 0.00048065...   \n",
       "4     [0.0, 0.0003533931, 0.00029845553, 0.000334326...   \n",
       "...                                                 ...   \n",
       "6285  [0.0, 0.00027235615, 0.00025388357, 0.00031370...   \n",
       "6286  [0.0, 0.026120104, 0.0, 0.0, 0.028340477, 0.02...   \n",
       "6287  [0.0, 0.00036221143, 0.0002952378, 0.000558458...   \n",
       "6288  [0.0, 0.00060361286, 0.0047984445, 0.0, 0.0003...   \n",
       "6289  [0.0, 0.00045896962, 0.00050114945, 5.0468183,...   \n",
       "\n",
       "                                        predicted_label  \n",
       "0     [0, 3, 4, 4, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, ...  \n",
       "1     [0, 0, 0, 0, 0, 0, 3, 4, 4, 4, 4, 4, 4, 4, 4, ...  \n",
       "2     [0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3     [0, 0, 0, 0, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, ...  \n",
       "...                                                 ...  \n",
       "6285  [0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 0, 0, 0, 0, ...  \n",
       "6286  [6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...  \n",
       "6287  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "6288  [0, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "6289  [0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[6290 rows x 5 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross-Lingual Transfer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1_score(trainer, dataset):\n",
    "    pred = trainer.predict(dataset)\n",
    "    # print(pred)\n",
    "    return pred.metrics[\"test_f1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/.conda/envs/raj/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_pred.predictions  [[[ 1.58810890e+00 -1.54733741e+00 -1.16104412e+00 ... -1.18324034e-01\n",
      "    6.07745647e-01  8.29567850e-01]\n",
      "  [ 8.42776012e+00 -1.83464015e+00 -1.98027217e+00 ... -1.47973204e+00\n",
      "   -9.90022540e-01 -2.12912011e+00]\n",
      "  [ 8.18541241e+00 -2.04214263e+00 -2.07078791e+00 ... -1.19023955e+00\n",
      "   -1.08549869e+00 -1.62960565e+00]\n",
      "  ...\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]]\n",
      "\n",
      " [[ 2.21413779e+00 -1.06343709e-01 -7.73303926e-01 ... -1.57930002e-01\n",
      "   -8.44027758e-01 -1.38618600e+00]\n",
      "  [ 8.95561600e+00 -2.15668750e+00 -1.32324958e+00 ... -9.68546867e-01\n",
      "   -2.01575851e+00 -1.51405501e+00]\n",
      "  [-1.73184466e+00  6.92158031e+00 -1.02179313e+00 ... -1.79805899e+00\n",
      "   -6.97338700e-01 -3.54025173e+00]\n",
      "  ...\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]]\n",
      "\n",
      " [[ 2.56540108e+00 -7.35994399e-01 -1.28308940e+00 ... -6.49473727e-01\n",
      "   -5.82994223e-01 -1.17166507e+00]\n",
      "  [ 8.17812157e+00 -1.99378502e+00 -1.85384429e+00 ... -1.16500735e+00\n",
      "   -1.25930882e+00 -2.04206800e+00]\n",
      "  [ 7.36372185e+00 -1.65511858e+00 -1.64693677e+00 ... -1.09843051e+00\n",
      "   -1.05448127e+00 -2.01251626e+00]\n",
      "  ...\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 2.44822717e+00 -1.25697684e+00 -1.59315753e+00 ...  3.72336209e-01\n",
      "   -5.55928469e-01 -1.19245958e+00]\n",
      "  [ 9.07313251e+00 -2.12169170e+00 -1.82705688e+00 ... -1.10593069e+00\n",
      "   -1.51114154e+00 -1.97564757e+00]\n",
      "  [ 8.97443104e+00 -2.28998661e+00 -1.68383825e+00 ... -1.41383791e+00\n",
      "   -1.46330619e+00 -1.67838287e+00]\n",
      "  ...\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]]\n",
      "\n",
      " [[ 2.74070883e+00 -1.32426572e+00 -1.64338088e+00 ... -5.70708692e-01\n",
      "   -5.76035157e-02 -8.81662011e-01]\n",
      "  [ 8.95661163e+00 -2.03582621e+00 -1.76550698e+00 ... -1.35723054e+00\n",
      "   -1.32617915e+00 -1.84942186e+00]\n",
      "  [ 5.84744740e+00 -1.95638537e+00 -3.22423339e+00 ... -1.99412131e+00\n",
      "    1.80183399e+00 -1.00187361e+00]\n",
      "  ...\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]]\n",
      "\n",
      " [[ 1.79468465e+00 -1.42850208e+00 -1.53862309e+00 ... -8.97218347e-01\n",
      "    6.75569475e-01  6.33624196e-01]\n",
      "  [-1.14681005e+00 -8.38434935e-01 -2.82179689e+00 ... -1.06865489e+00\n",
      "    5.90797520e+00 -7.89883077e-01]\n",
      "  [-1.08447814e+00 -3.98233771e+00 -5.41180909e-01 ...  1.10364246e+00\n",
      "    4.09297317e-01  6.56046009e+00]\n",
      "  ...\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]]]\n",
      "F1-score of [de] model on [de] dataset: 0.866\n"
     ]
    }
   ],
   "source": [
    "f1_scores = defaultdict(dict)\n",
    "f1_scores[\"de\"][\"de\"] = get_f1_score(trainer, panx_de_encoded[\"test\"])\n",
    "print(f\"F1-score of [de] model on [de] dataset: {f1_scores['de']['de']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids  tensor([[     0, 101681,    262,     66,    437, 124588,   6594,  19998,   1815,\n",
      "             22,  25971,   2472,    701,      2]], device='cuda:0')\n",
      "Shape of outputs: torch.Size([1, 14, 7])\n",
      "predictions  tensor([[0, 1, 2, 2, 0, 0, 0, 0, 3, 0, 5, 6, 6, 0]], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁Jeff</td>\n",
       "      <td>▁De</td>\n",
       "      <td>an</td>\n",
       "      <td>▁est</td>\n",
       "      <td>▁informatic</td>\n",
       "      <td>ien</td>\n",
       "      <td>▁chez</td>\n",
       "      <td>▁Google</td>\n",
       "      <td>▁en</td>\n",
       "      <td>▁Cali</td>\n",
       "      <td>for</td>\n",
       "      <td>nie</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tags</th>\n",
       "      <td>O</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0      1      2      3     4            5    6      7        8    9   \\\n",
       "Tokens  <s>  ▁Jeff    ▁De     an  ▁est  ▁informatic  ien  ▁chez  ▁Google  ▁en   \n",
       "Tags      O  B-PER  I-PER  I-PER     O            O    O      O    B-ORG    O   \n",
       "\n",
       "           10     11     12    13  \n",
       "Tokens  ▁Cali    for    nie  </s>  \n",
       "Tags    B-LOC  I-LOC  I-LOC     O  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_fr = \"Jeff Dean est informaticien chez Google en Californie\"\n",
    "tag_text(text_fr, tags, trainer.model, xlmr_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_lang_performance(lang, trainer):\n",
    "    panx_ds = encode_panx_dataset(panx_ds_combined[lang])\n",
    "    return get_f1_score(trainer, panx_ds[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/raj/.cache/huggingface/datasets/xtreme/PAN-X.fr/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-2a4fd6a917004b8f.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b3837b9dde84c37ae56621ad1db0c26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2290 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/raj/.cache/huggingface/datasets/xtreme/PAN-X.fr/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-4595e33651fa990a.arrow\n",
      "/home/raj/.conda/envs/raj/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_pred.predictions  [[[ 9.3874633e-01 -9.4102256e-02 -4.9761397e-01 ...  8.0920972e-02\n",
      "   -7.6059830e-01 -4.0336564e-01]\n",
      "  [ 8.8682432e+00 -2.1189246e+00 -1.9750894e+00 ... -1.3575431e+00\n",
      "   -1.5486699e+00 -1.9427141e+00]\n",
      "  [ 8.7790251e+00 -2.0927315e+00 -1.8353462e+00 ... -1.3712826e+00\n",
      "   -1.4820647e+00 -1.9989020e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[ 2.2014942e+00 -9.8080510e-01 -1.5690372e+00 ... -7.8410155e-01\n",
      "    5.7924844e-02 -3.9798570e-01]\n",
      "  [ 8.0690184e+00 -1.3143944e+00 -2.8024993e+00 ... -2.2826414e+00\n",
      "   -7.2487587e-01 -2.5783691e+00]\n",
      "  [ 7.8918805e+00 -1.7571820e+00 -2.3320544e+00 ... -1.7937318e+00\n",
      "   -1.2960677e+00 -2.2815628e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[ 2.6871381e+00  9.4230658e-01  2.2810771e-01 ... -1.3309612e+00\n",
      "   -8.7146622e-01 -2.0677865e+00]\n",
      "  [ 8.8665733e+00 -2.1397781e+00 -1.2921324e+00 ... -1.3799884e+00\n",
      "   -1.6676785e+00 -2.0082846e+00]\n",
      "  [ 7.4999051e+00 -1.0665040e-01 -2.4754577e+00 ... -2.0572455e+00\n",
      "   -8.0391800e-01 -2.6348743e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 9.6276939e-01 -1.7562466e+00 -1.2332789e+00 ...  2.0526118e+00\n",
      "   -5.6039137e-01 -9.8382837e-01]\n",
      "  [ 8.5434799e+00 -2.1396873e+00 -2.0739326e+00 ... -9.1815090e-01\n",
      "   -1.5712918e+00 -2.1615539e+00]\n",
      "  [-8.3278280e-01  5.3329945e-01 -3.1286111e+00 ... -1.1476228e+00\n",
      "    2.3272085e+00 -2.5964742e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[-9.7449535e-01 -7.2017634e-01  6.6817588e-01 ...  3.8382840e+00\n",
      "   -1.7878532e+00 -1.1063348e+00]\n",
      "  [-1.2662114e+00  1.2266074e+00 -2.4297967e+00 ... -6.0504925e-01\n",
      "    1.0236692e+00 -3.4404812e+00]\n",
      "  [-1.4005526e+00 -2.4113972e+00  8.5274357e-01 ...  5.1891570e+00\n",
      "   -2.6965842e+00 -6.8489546e-01]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[ 1.4219255e+00  9.0052027e-01  1.6009060e-01 ... -7.6947647e-01\n",
      "   -8.6034018e-01 -1.4439776e+00]\n",
      "  [ 8.8037834e+00 -1.9263002e+00 -1.9103287e+00 ... -1.3497027e+00\n",
      "   -1.6168348e+00 -2.1331501e+00]\n",
      "  [ 8.6015615e+00 -1.8456236e+00 -1.7663169e+00 ... -1.3304447e+00\n",
      "   -1.5662888e+00 -2.1761217e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]]\n",
      "F1-score of [de] model on [fr] dataset: 0.708\n"
     ]
    }
   ],
   "source": [
    "f1_scores[\"de\"][\"fr\"] = evaluate_lang_performance(\"fr\", trainer)\n",
    "print(f\"F1-score of [de] model on [fr] dataset: {f1_scores['de']['fr']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of [de] model on [fr] dataset: 0.708\n"
     ]
    }
   ],
   "source": [
    "print(f\"F1-score of [de] model on [fr] dataset: {f1_scores['de']['fr']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/raj/.cache/huggingface/datasets/xtreme/PAN-X.it/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-0aca5f2553f92f34.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/raj/.cache/huggingface/datasets/xtreme/PAN-X.it/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-6600f7a976c53871.arrow\n",
      "Loading cached processed dataset at /home/raj/.cache/huggingface/datasets/xtreme/PAN-X.it/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-838480ede753f20c.arrow\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_pred.predictions  [[[ 2.5502539e+00 -1.4318651e+00 -1.8286299e+00 ... -6.7941435e-02\n",
      "    3.5958558e-02 -6.8693113e-01]\n",
      "  [ 8.8441820e+00 -2.2733421e+00 -1.8012979e+00 ... -1.6386027e+00\n",
      "   -9.6152818e-01 -1.9637138e+00]\n",
      "  [ 8.6686287e+00 -2.3820424e+00 -1.8836832e+00 ... -1.3673038e+00\n",
      "   -8.4958690e-01 -1.7506460e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[ 3.4128842e+00 -1.7313335e+00 -1.8809266e+00 ... -1.2290237e+00\n",
      "    6.2051046e-01 -2.4727222e-01]\n",
      "  [ 8.5981674e+00 -2.1070921e+00 -2.0966318e+00 ... -1.4671975e+00\n",
      "   -9.4185996e-01 -1.9593697e+00]\n",
      "  [ 8.9099751e+00 -2.5117991e+00 -1.9528372e+00 ... -1.2018976e+00\n",
      "   -1.5825670e+00 -1.6754193e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[ 6.3491005e-01 -9.9222463e-01 -1.0258853e+00 ...  2.3366179e+00\n",
      "   -7.3287839e-01 -1.1269001e+00]\n",
      "  [-1.4105886e+00  1.1617996e+00 -2.0813396e+00 ... -4.8179200e-01\n",
      "    1.0438744e+00 -2.7164583e+00]\n",
      "  [-1.7634588e+00 -2.5272744e+00  6.1695737e-01 ...  5.8900228e+00\n",
      "   -2.5383272e+00  6.7783296e-01]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-8.7941623e-01  1.6384639e+00  2.7146349e+00 ...  5.9463936e-01\n",
      "   -1.6837078e+00 -1.4888500e+00]\n",
      "  [ 3.4799078e+00  5.7442111e-01 -2.9759486e+00 ... -1.6990255e+00\n",
      "   -6.1664331e-01 -3.0363708e+00]\n",
      "  [ 2.4931605e+00 -5.5987138e-01 -2.0882869e+00 ... -2.6777411e-02\n",
      "   -1.8514657e+00 -1.9457873e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[-6.1251122e-01 -9.9419039e-01 -8.9730196e-02 ...  3.7778907e+00\n",
      "   -1.4834591e+00 -1.1299211e+00]\n",
      "  [-1.1520399e+00  1.0736293e-01 -3.0507598e+00 ... -1.0929926e-01\n",
      "    5.5004227e-01 -2.8211470e+00]\n",
      "  [-1.1072005e+00 -1.9929436e+00 -1.1330886e+00 ...  3.6589689e+00\n",
      "   -1.5750130e+00 -1.2462573e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[-3.8986173e-01 -4.8292983e-01  3.6239409e-01 ...  3.1462030e+00\n",
      "   -1.8662146e+00 -1.3473259e+00]\n",
      "  [-2.1434312e+00  2.0203676e+00 -3.0915504e+00 ... -1.2662475e+00\n",
      "    6.7385197e-01 -3.5776105e+00]\n",
      "  [-1.5528898e+00 -2.9803059e+00  2.2962737e+00 ...  6.7470355e+00\n",
      "   -3.5014954e+00  4.3842694e-01]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]]\n",
      "F1-score of [de] model on [it] dataset: 0.676\n"
     ]
    }
   ],
   "source": [
    "f1_scores[\"de\"][\"it\"] = evaluate_lang_performance(\"it\", trainer)\n",
    "print(f\"F1-score of [de] model on [it] dataset: {f1_scores['de']['it']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/raj/.cache/huggingface/datasets/xtreme/PAN-X.en/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-85e11aea0c209c3a.arrow\n",
      "Loading cached processed dataset at /home/raj/.cache/huggingface/datasets/xtreme/PAN-X.en/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-4d29ec81a064ef61.arrow\n",
      "Loading cached processed dataset at /home/raj/.cache/huggingface/datasets/xtreme/PAN-X.en/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-4c06b3c347f3c313.arrow\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_pred.predictions  [[[ 3.4219425e+00 -1.4640983e+00 -1.8617383e+00 ... -4.5360196e-01\n",
      "   -4.8252627e-02 -1.4093765e+00]\n",
      "  [ 9.1959848e+00 -2.3616447e+00 -1.6479107e+00 ... -1.1377004e+00\n",
      "   -1.5848397e+00 -1.6858253e+00]\n",
      "  [ 9.0824814e+00 -2.3978324e+00 -1.8293812e+00 ... -1.2100713e+00\n",
      "   -1.4866109e+00 -1.5420157e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[ 1.2914858e+00  1.2772928e+00  1.1472337e+00 ... -9.0526408e-01\n",
      "   -1.2912399e+00 -1.5049495e+00]\n",
      "  [-1.0600867e+00  7.4186397e+00 -5.9654629e-01 ... -2.2896416e+00\n",
      "   -8.8611507e-01 -3.3422954e+00]\n",
      "  [-1.8592557e+00 -4.5212322e-01  7.5580192e+00 ...  7.1593362e-01\n",
      "   -2.8311934e+00 -9.9291545e-01]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[ 1.1798144e-01 -5.1582003e-01 -5.5620325e-01 ...  1.0603747e+00\n",
      "   -4.7184280e-01  1.1285406e-01]\n",
      "  [-1.4906929e+00  2.2501042e+00 -3.4451385e+00 ... -1.8456990e+00\n",
      "    3.4157758e+00 -2.9888420e+00]\n",
      "  [-2.5747488e+00 -1.4665306e+00  1.5717817e-03 ...  2.3869801e+00\n",
      "   -4.4537686e-02  1.7893642e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-2.7323562e-01  2.2928751e+00  2.5653858e+00 ... -5.2300519e-01\n",
      "   -1.3366021e+00 -2.1063685e+00]\n",
      "  [-1.9722366e+00  7.7082782e+00 -6.7598516e-01 ... -2.1847262e+00\n",
      "   -6.6295743e-01 -3.2509766e+00]\n",
      "  [-1.7254125e+00 -6.4924634e-01  7.6543207e+00 ...  1.0518963e+00\n",
      "   -2.9252930e+00 -8.8566083e-01]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[ 2.5826426e+00 -1.4269677e+00 -2.0654078e+00 ... -8.7043548e-01\n",
      "    3.6807972e-01 -2.9263452e-01]\n",
      "  [ 8.5426331e+00 -2.0435641e+00 -2.0403047e+00 ... -1.3998542e+00\n",
      "   -1.7574257e+00 -2.2571654e+00]\n",
      "  [ 7.9755473e+00 -1.7528096e+00 -2.4392552e+00 ... -1.6855417e+00\n",
      "   -1.1623430e+00 -2.2171462e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[ 4.4211984e-01 -1.5692869e+00 -8.1406569e-01 ...  1.7164423e+00\n",
      "   -2.1986085e-01 -7.4873173e-01]\n",
      "  [-2.3157644e-01  3.4778919e-02 -2.9415836e+00 ... -1.0395268e+00\n",
      "    1.8011054e+00 -2.8817043e+00]\n",
      "  [ 1.5438330e-01 -3.4277785e+00  3.5633171e-01 ...  4.7311201e+00\n",
      "   -2.2460899e+00  7.5485748e-01]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]]\n",
      "F1-score of [de] model on [en] dataset: 0.602\n"
     ]
    }
   ],
   "source": [
    "f1_scores[\"de\"][\"en\"] = evaluate_lang_performance(\"en\", trainer)\n",
    "print(f\"F1-score of [de] model on [en] dataset: {f1_scores['de']['en']:.3f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When Does Zero-Shot Transfer Make Sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc,os\n",
    "def fine_tuning_training_on_single_corpus(dataset, num_samples):\n",
    "    \"\"\"\n",
    "    Function to train the model on a single corpus of data.\n",
    "\n",
    "    Parameters:\n",
    "    dataset (DatasetDict): The dataset to train on. It should be a HuggingFace DatasetDict containing 'train', 'validation' and 'test' splits.\n",
    "    num_samples (int): The number of samples from the training set to use for training.\n",
    "\n",
    "    Returns:\n",
    "    results (pd.DataFrame): A pandas DataFrame containing the number of training samples used and the F1 score on the test set.\n",
    "    \"\"\"\n",
    "    gc.collect()\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "    torch.cuda.set_device(0)\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.set_device(1)\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # Shuffle the training data and select the first 'num_samples' examples.\n",
    "    train_ds = dataset[\"train\"].shuffle(seed=42).select(range(num_samples))\n",
    "    # The validation and test sets are not shuffled or truncated.\n",
    "    valid_ds = dataset[\"validation\"]\n",
    "    test_ds = dataset[\"test\"]\n",
    "\n",
    "    # Update the logging steps in the training arguments to log progress after each batch.\n",
    "    training_args.logging_steps = len(train_ds) // batch_size\n",
    "\n",
    "    # Initialize a Trainer instance. This is a HuggingFace class that handles training.\n",
    "    trainer = Trainer(model_init=model_init, args=training_args,\n",
    "        data_collator=data_collator, compute_metrics=compute_metrics,\n",
    "        train_dataset=train_ds, eval_dataset=valid_ds, tokenizer=xlmr_tokenizer)\n",
    "    \n",
    "    # Train the model.\n",
    "    trainer.train()\n",
    "\n",
    "    # If the training arguments specify to push the model to the HuggingFace model hub, do so with a commit message.\n",
    "    if training_args.push_to_hub:\n",
    "        trainer.push_to_hub(commit_message=\"Training completed!\")\n",
    "    \n",
    "    # After training, compute the F1 score on the test set.\n",
    "    f1_score = get_f1_score(trainer, test_ds)\n",
    "\n",
    "    # Return the results as a pandas DataFrame.\n",
    "    return pd.DataFrame.from_dict(\n",
    "        {\"num_samples\": [len(train_ds)], \"f1_score\": [f1_score]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/raj/.cache/huggingface/datasets/xtreme/PAN-X.fr/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-e0f733454a77c6e3.arrow\n",
      "Loading cached processed dataset at /home/raj/.cache/huggingface/datasets/xtreme/PAN-X.fr/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-428c0ad2f890b9e4.arrow\n",
      "Loading cached processed dataset at /home/raj/.cache/huggingface/datasets/xtreme/PAN-X.fr/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-4595e33651fa990a.arrow\n"
     ]
    }
   ],
   "source": [
    "panx_fr_encoded = encode_panx_dataset(panx_ds_combined[\"fr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /home/raj/.cache/huggingface/datasets/xtreme/PAN-X.fr/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-3fabc88089e55de9.arrow\n",
      "/home/raj/.conda/envs/raj/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/home/raj/.conda/envs/raj/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:32, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.374720</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.415400</td>\n",
       "      <td>1.184717</td>\n",
       "      <td>0.152361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.415400</td>\n",
       "      <td>1.096724</td>\n",
       "      <td>0.186587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_pred.predictions  [[[ 2.1450615e-01  2.2584781e-01 -6.2039900e-01 ...  4.6537733e-01\n",
      "   -2.4575743e-01 -3.1688869e-02]\n",
      "  [ 8.4873492e-01 -3.5211381e-01 -7.5235653e-01 ...  1.6161062e-01\n",
      "   -5.1023936e-01 -7.9878502e-02]\n",
      "  [ 8.3297646e-01 -4.5436919e-01 -5.8286184e-01 ...  2.3797962e-01\n",
      "   -7.0552105e-01  8.6460412e-02]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[ 4.4832173e-01 -1.7036326e-01 -8.1720924e-01 ... -2.3061469e-02\n",
      "   -5.0462365e-01  3.8416982e-01]\n",
      "  [ 1.5309983e+00 -6.3777477e-01 -9.9176085e-01 ...  2.4623279e-01\n",
      "   -3.8963774e-01 -5.3715914e-01]\n",
      "  [ 1.3340960e+00 -9.0318024e-01 -8.3743954e-01 ...  3.7898159e-01\n",
      "   -6.0202700e-01 -1.2972145e-01]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[ 4.0052477e-01 -2.2850126e-02 -8.0054992e-01 ...  1.5498173e-01\n",
      "   -5.2998251e-01  2.5984335e-01]\n",
      "  [ 3.3733413e+00 -3.7155682e-01 -8.6471456e-01 ...  1.4547735e-02\n",
      "   -6.5075719e-01 -7.9403400e-01]\n",
      "  [ 3.7483430e+00 -2.9808873e-01 -5.4874712e-01 ...  8.1750810e-02\n",
      "   -5.0227344e-01 -1.0333493e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 8.8950612e-02  1.6331244e-01 -6.4458209e-01 ...  2.2175002e-01\n",
      "   -5.5166453e-01  8.5224375e-02]\n",
      "  [ 3.5226293e+00 -7.4166119e-01 -9.1918266e-01 ... -2.7772725e-02\n",
      "   -5.9558755e-01 -1.3567798e+00]\n",
      "  [ 3.4467936e+00 -7.7845752e-01 -2.6147109e-01 ...  4.8829734e-02\n",
      "   -5.0580084e-01 -1.3646358e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[ 3.7631080e-01 -1.6385335e-01 -7.9355395e-01 ... -4.7072291e-02\n",
      "   -4.7208476e-01  3.9256245e-01]\n",
      "  [ 1.2322551e+00 -6.2276834e-01 -9.5336044e-01 ...  2.8097934e-01\n",
      "   -3.5633293e-01 -4.7319645e-01]\n",
      "  [ 8.9146864e-01 -7.0865107e-01 -8.6511481e-01 ...  1.0903852e-01\n",
      "   -4.4421050e-01 -7.2048932e-02]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[ 3.6716968e-01 -5.3404644e-04 -7.7473909e-01 ...  6.1075620e-02\n",
      "   -4.6035650e-01  3.1495589e-01]\n",
      "  [ 7.6576483e-01 -4.5360908e-01 -9.6083665e-01 ...  1.2044445e-01\n",
      "   -4.7731087e-01  3.4577101e-03]\n",
      "  [ 9.8231363e-01 -6.3678026e-01 -7.7106583e-01 ...  2.3609948e-01\n",
      "   -4.7647449e-01  1.8479884e-01]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]]\n",
      "eval_pred.predictions  [[[-2.5338084e-01  2.9029596e-01 -5.4243517e-01 ...  5.5301821e-01\n",
      "   -2.1435638e-01  9.0567946e-02]\n",
      "  [ 3.4173894e-01 -3.2245111e-01 -7.4479270e-01 ...  3.4266376e-01\n",
      "   -3.6503968e-01 -5.2906737e-02]\n",
      "  [ 4.1221333e-01 -4.3860564e-01 -5.6256819e-01 ...  4.9873281e-01\n",
      "   -5.6148601e-01  1.3081244e-01]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[ 3.3445936e-01 -1.8892217e-01 -7.9532862e-01 ...  5.7834610e-03\n",
      "   -4.9235636e-01  4.1549194e-01]\n",
      "  [ 1.2939655e+00 -8.3426446e-01 -5.2579659e-01 ...  3.5204473e-01\n",
      "    9.6206665e-02 -1.2339568e+00]\n",
      "  [ 2.7358687e-01 -6.3179862e-01  8.6772859e-02 ...  5.0087833e-01\n",
      "    2.0560730e-01 -5.3388339e-01]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[ 3.5271820e-01 -3.2667257e-02 -7.8198469e-01 ...  1.7367658e-01\n",
      "   -5.1129901e-01  2.9659036e-01]\n",
      "  [ 4.4065342e+00 -7.0077497e-01 -7.1552324e-01 ... -2.8082073e-02\n",
      "   -7.9552370e-01 -1.1444108e+00]\n",
      "  [ 4.3656850e+00 -6.4719075e-01 -5.2666169e-01 ...  8.1846446e-02\n",
      "   -7.2388911e-01 -1.0915112e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-8.6672373e-02  1.0077769e-01 -6.7633659e-01 ...  2.2074226e-01\n",
      "   -5.3484654e-01  2.7873126e-01]\n",
      "  [ 3.9614563e+00 -9.6540350e-01 -9.2405248e-01 ... -1.1027962e-02\n",
      "   -8.3145499e-01 -1.4455407e+00]\n",
      "  [ 3.4300971e+00 -1.0143833e+00 -8.9119434e-02 ...  8.2505286e-02\n",
      "   -5.3089917e-01 -1.3450552e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[ 1.2415538e-01 -1.2769420e-01 -7.5503498e-01 ...  5.0968267e-02\n",
      "   -4.5046923e-01  4.3793878e-01]\n",
      "  [ 1.2555144e+00 -8.7199736e-01 -7.7866620e-01 ...  4.5016462e-01\n",
      "   -2.5050648e-02 -1.0598451e+00]\n",
      "  [ 6.5512997e-01 -1.0307914e+00 -7.2123700e-01 ...  2.9204243e-01\n",
      "   -2.7099484e-01 -3.5160804e-01]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[ 1.3323623e-01  2.8466165e-02 -7.6390833e-01 ...  8.1833810e-02\n",
      "   -4.3905509e-01  3.6501893e-01]\n",
      "  [ 5.9310969e-02 -5.1036859e-01 -1.0974047e+00 ...  4.9221495e-01\n",
      "   -3.2357770e-01 -9.3358278e-02]\n",
      "  [ 5.7055610e-01 -6.3898349e-01 -7.4918413e-01 ...  5.5441535e-01\n",
      "   -4.3018186e-01  2.3391889e-01]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]]\n",
      "eval_pred.predictions  [[[-1.8265086e-01  2.7713013e-01 -5.5636752e-01 ...  3.9184099e-01\n",
      "   -2.9983020e-01  1.3956332e-01]\n",
      "  [ 1.0894139e-01 -2.7378377e-01 -6.4855057e-01 ...  3.5079694e-01\n",
      "   -2.7447385e-01 -1.2812759e-01]\n",
      "  [ 3.2779348e-01 -4.1748497e-01 -4.6168220e-01 ...  5.0184608e-01\n",
      "   -5.3797179e-01  1.2929325e-01]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[-8.5955434e-02 -3.0950584e-02 -7.2672909e-01 ...  1.7590715e-01\n",
      "   -4.5783022e-01  4.3096858e-01]\n",
      "  [ 2.4725852e+00 -9.0585423e-01 -5.5683637e-01 ...  4.4525333e-02\n",
      "    6.5809116e-02 -1.2525702e+00]\n",
      "  [ 1.1009982e+00 -7.3146248e-01 -1.3142824e-02 ...  1.1633907e-01\n",
      "    4.9080409e-02 -5.3456920e-01]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[ 3.8547671e-01 -2.9570818e-02 -7.7414751e-01 ...  1.1360940e-01\n",
      "   -5.2734524e-01  3.0320796e-01]\n",
      "  [ 4.7809105e+00 -7.7975959e-01 -6.1189592e-01 ... -3.3789253e-01\n",
      "   -9.8029780e-01 -1.1392916e+00]\n",
      "  [ 4.7217879e+00 -7.2382307e-01 -4.5759115e-01 ... -2.1062931e-01\n",
      "   -9.2403066e-01 -1.0565344e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-3.3142442e-01  2.9440695e-01 -5.4420167e-01 ...  3.4902257e-01\n",
      "   -5.0688440e-01  9.2112482e-02]\n",
      "  [ 4.4987755e+00 -1.0494505e+00 -7.9688853e-01 ... -3.5169101e-01\n",
      "   -9.8569202e-01 -1.4390945e+00]\n",
      "  [ 3.7647924e+00 -1.0308144e+00  1.4482737e-03 ... -2.3533618e-01\n",
      "   -6.8651235e-01 -1.1953733e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[-1.7647652e-01  4.2447776e-02 -6.5993172e-01 ...  1.0383052e-01\n",
      "   -4.1981068e-01  4.4514829e-01]\n",
      "  [ 2.4970789e+00 -7.8662634e-01 -6.5203685e-01 ...  8.0690891e-02\n",
      "    1.7631489e-01 -1.2617950e+00]\n",
      "  [ 1.6398910e+00 -1.1041919e+00 -5.8337867e-01 ...  2.5841670e-02\n",
      "   -1.6937643e-01 -5.1448810e-01]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[ 7.0815653e-02  9.4705783e-02 -7.4087918e-01 ...  8.4233344e-02\n",
      "   -4.7886741e-01  3.5354242e-01]\n",
      "  [ 2.6773391e-02 -5.0917560e-01 -1.1081611e+00 ...  3.3449489e-01\n",
      "   -2.2817013e-01 -2.2305962e-01]\n",
      "  [ 5.4337341e-01 -7.0339656e-01 -6.1346906e-01 ...  6.6012442e-01\n",
      "   -3.8577560e-01  1.2442038e-01]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_pred.predictions  [[[ 3.16441298e-01 -5.24596348e-02 -7.00767100e-01 ...  5.64668030e-02\n",
      "   -5.27383387e-01  3.24514061e-01]\n",
      "  [ 4.26920557e+00 -6.99280620e-01 -8.93756032e-01 ... -4.18901443e-01\n",
      "   -1.17842507e+00 -8.49378407e-01]\n",
      "  [ 4.45716906e+00 -6.66810691e-01 -5.99506497e-01 ... -2.71522611e-01\n",
      "   -1.12872553e+00 -8.81446421e-01]\n",
      "  ...\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]]\n",
      "\n",
      " [[ 9.54382718e-02  1.41819462e-01 -6.53472483e-01 ...  2.24040046e-01\n",
      "   -3.80137086e-01  2.28751019e-01]\n",
      "  [ 3.45800853e+00 -6.83954716e-01 -5.57046890e-01 ...  1.86908826e-01\n",
      "    1.29003048e-01 -1.33734632e+00]\n",
      "  [ 3.08578134e+00 -1.04280221e+00 -4.92998928e-01 ...  4.43333954e-01\n",
      "   -3.64145339e-01 -1.11945474e+00]\n",
      "  ...\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]]\n",
      "\n",
      " [[ 3.72319341e-01 -3.84028181e-02 -7.03812361e-01 ...  1.05395116e-01\n",
      "   -4.61297005e-01  2.50099152e-01]\n",
      "  [ 3.55991888e+00 -1.75937796e+00 -3.82870585e-01 ...  2.09194973e-01\n",
      "   -8.92498076e-01 -7.12360382e-01]\n",
      "  [ 1.64460981e+00 -7.42058277e-01 -7.02447593e-01 ...  6.02967218e-02\n",
      "   -4.68755037e-01 -6.48667932e-01]\n",
      "  ...\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-3.36454034e-01  3.20105642e-01 -5.59880018e-01 ...  3.99250805e-01\n",
      "   -3.83811235e-01  2.03517348e-01]\n",
      "  [ 4.39214087e+00 -6.50222361e-01 -6.25198960e-01 ... -1.80027455e-01\n",
      "   -1.12641907e+00 -7.42129743e-01]\n",
      "  [-4.83870089e-01 -3.70640367e-01  1.66415676e-01 ...  5.51888227e-01\n",
      "    5.47179818e-01 -6.93220377e-01]\n",
      "  ...\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]]\n",
      "\n",
      " [[-5.98327458e-01  1.31733239e-01 -6.20871127e-01 ...  3.16481173e-01\n",
      "   -2.71008492e-01  3.99251640e-01]\n",
      "  [-1.58853447e+00 -5.75109839e-01 -2.95960367e-01 ...  6.02058947e-01\n",
      "    2.52666533e-01 -6.50511682e-01]\n",
      "  [-1.44878614e+00 -5.85673094e-01  9.90647525e-02 ...  6.89464509e-01\n",
      "    3.68076593e-01 -5.82848907e-01]\n",
      "  ...\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]]\n",
      "\n",
      " [[ 3.53051513e-01 -3.41694318e-02 -7.51820207e-01 ...  1.88349232e-01\n",
      "   -4.80357230e-01  2.19026864e-01]\n",
      "  [ 4.67706537e+00 -8.52393866e-01 -6.81269944e-01 ... -3.99380833e-01\n",
      "   -1.04950273e+00 -1.04991198e+00]\n",
      "  [ 4.67391539e+00 -7.43321300e-01 -5.79567671e-01 ... -2.71743953e-01\n",
      "   -1.05969000e+00 -1.10175109e+00]\n",
      "  ...\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_samples</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250</td>\n",
       "      <td>0.173469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_samples  f1_score\n",
       "0          250  0.173469"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gc.collect()\n",
    "metrics_df = fine_tuning_training_on_single_corpus(panx_fr_encoded, 250)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.set_device(1)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "num_samples = [500, 1000, 2000, 4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /home/raj/.cache/huggingface/datasets/xtreme/PAN-X.fr/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-3fabc88089e55de9.arrow\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:40, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.081651</td>\n",
       "      <td>0.167514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.148800</td>\n",
       "      <td>0.723332</td>\n",
       "      <td>0.516304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.148800</td>\n",
       "      <td>0.630105</td>\n",
       "      <td>0.597518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_pred.predictions  [[[-5.72805643e-01  4.34153616e-01 -2.53021210e-01 ...  2.97349155e-01\n",
      "   -3.47194731e-01 -1.00499466e-01]\n",
      "  [ 1.22842327e-01 -3.59794706e-01 -3.85554463e-01 ...  7.92291611e-02\n",
      "   -4.05806601e-01  7.89473951e-03]\n",
      "  [ 1.37870207e-01 -4.76961523e-01 -2.78281242e-01 ...  1.03871353e-01\n",
      "   -6.00300908e-01  1.63836241e-01]\n",
      "  ...\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]]\n",
      "\n",
      " [[-4.99726087e-01  2.00697154e-01 -5.28362393e-01 ...  3.97398561e-01\n",
      "   -3.97910744e-01  3.52852523e-01]\n",
      "  [ 3.24407339e+00 -1.04810715e+00 -3.71944785e-01 ... -2.48234391e-01\n",
      "    2.01837912e-01 -1.13919866e+00]\n",
      "  [ 2.15933561e+00 -1.26516032e+00 -5.66058755e-01 ... -1.09122038e-01\n",
      "   -1.53701723e-01 -3.23133916e-01]\n",
      "  ...\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]]\n",
      "\n",
      " [[-9.78773385e-02  3.86850536e-01 -5.80248713e-01 ...  2.76609242e-01\n",
      "   -2.90160120e-01  8.95957947e-02]\n",
      "  [ 4.72791576e+00 -7.93472230e-01 -5.31391561e-01 ... -7.87352920e-01\n",
      "   -4.94553149e-01 -1.18211913e+00]\n",
      "  [ 4.63139629e+00 -6.73357964e-01 -3.53844285e-01 ... -6.33164525e-01\n",
      "   -4.21541750e-01 -1.12774014e+00]\n",
      "  ...\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-8.90347660e-01  5.39420903e-01 -9.36318561e-02 ...  4.30305868e-01\n",
      "   -2.10200325e-01 -1.69678167e-01]\n",
      "  [ 4.77363634e+00 -1.33426940e+00 -8.01635385e-01 ... -6.08968019e-01\n",
      "   -5.24220645e-01 -1.61962581e+00]\n",
      "  [ 4.47275925e+00 -1.25264549e+00 -2.96658367e-01 ... -5.49637079e-01\n",
      "   -6.53022945e-01 -1.34277868e+00]\n",
      "  ...\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]]\n",
      "\n",
      " [[-9.61288273e-01  4.15461540e-01 -3.55071813e-01 ...  3.63431424e-01\n",
      "   -1.13689721e-01  1.92963377e-01]\n",
      "  [ 2.74514961e+00 -9.59082723e-01 -2.94443130e-01 ... -1.10562243e-01\n",
      "    2.60015845e-01 -9.75718498e-01]\n",
      "  [ 2.05529237e+00 -1.21572959e+00 -5.56991339e-01 ... -1.45719379e-01\n",
      "   -1.04989052e-01 -2.61866093e-01]\n",
      "  ...\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]]\n",
      "\n",
      " [[-1.03258073e+00  9.42171097e-01  6.80239871e-02 ...  5.31122267e-01\n",
      "   -1.31157443e-01 -6.59803748e-02]\n",
      "  [ 1.23259008e-01 -4.47892576e-01 -8.61061692e-01 ...  2.95456707e-01\n",
      "   -2.46595383e-01 -2.91060209e-02]\n",
      "  [ 4.31810021e-02 -5.88941872e-01 -5.27173817e-01 ...  6.54553831e-01\n",
      "   -2.89326459e-01  8.48140270e-02]\n",
      "  ...\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]]]\n",
      "eval_pred.predictions  [[[ 1.6559488e-01  1.3352312e-02 -7.3599881e-01 ...  3.6279038e-03\n",
      "   -5.7344782e-01  3.7353256e-01]\n",
      "  [-1.7296582e+00  1.6819792e+00  8.6206812e-01 ... -4.9299544e-01\n",
      "   -5.1261596e-02 -6.2430751e-01]\n",
      "  [-9.9192607e-01  8.1278700e-01  7.9734576e-01 ... -1.1159819e-01\n",
      "   -8.0166054e-01  1.9577298e-01]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[-4.6384358e-01  9.6285328e-02 -8.1453913e-01 ...  4.6561527e-01\n",
      "   -5.5872381e-01  7.0891780e-01]\n",
      "  [ 5.0151744e+00 -1.1522003e+00 -1.1809782e+00 ... -1.1930981e+00\n",
      "   -3.5152483e-01 -6.9697130e-01]\n",
      "  [ 4.4034867e+00 -1.3410906e+00 -9.0211052e-01 ... -1.1278918e+00\n",
      "   -4.5953128e-01 -4.6440256e-01]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[-3.1058453e-02  2.5395101e-01 -7.5151783e-01 ...  2.4343330e-01\n",
      "   -5.0624371e-01  4.2524064e-01]\n",
      "  [ 5.4628811e+00 -1.0474585e+00 -1.4606504e+00 ... -1.1721332e+00\n",
      "   -1.2241645e+00 -5.2762210e-01]\n",
      "  [ 5.5779319e+00 -1.0226525e+00 -1.3366382e+00 ... -1.1423990e+00\n",
      "   -1.1920121e+00 -5.2793634e-01]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-1.1688434e+00  4.6207714e-01 -5.2623141e-01 ...  6.6736424e-01\n",
      "   -4.8598152e-01  4.0164703e-01]\n",
      "  [ 5.4997282e+00 -1.3537769e+00 -1.4163803e+00 ... -1.2440772e+00\n",
      "   -1.0770364e+00 -1.1870292e+00]\n",
      "  [ 5.2392521e+00 -1.3665525e+00 -1.2543297e+00 ... -1.2099063e+00\n",
      "   -1.3561547e+00 -7.0361084e-01]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[ 7.6784849e-02 -7.0022449e-02 -8.3358032e-01 ...  1.5250777e-01\n",
      "   -4.8192438e-01  6.2500530e-01]\n",
      "  [ 4.8685284e+00 -1.1238382e+00 -1.0905497e+00 ... -1.1603668e+00\n",
      "   -3.2239991e-01 -6.0136163e-01]\n",
      "  [ 4.1055036e+00 -1.4488363e+00 -8.4173858e-01 ... -1.1272714e+00\n",
      "   -4.5416296e-01 -2.3989528e-01]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[-8.7481312e-02  1.9586650e-01 -7.7941740e-01 ...  2.7084082e-01\n",
      "   -5.4638118e-01  5.0645393e-01]\n",
      "  [-1.9574223e+00  1.4038868e-01 -9.2675316e-01 ...  9.9547780e-01\n",
      "    6.8476909e-01 -3.4771472e-01]\n",
      "  [-1.7589736e+00 -1.4470588e-01 -6.0144389e-01 ...  1.7731721e+00\n",
      "    2.1213681e-01  2.6045799e-01]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]]\n",
      "eval_pred.predictions  [[[ 2.49346167e-01 -2.03467682e-02 -7.37439096e-01 ... -5.27660921e-02\n",
      "   -5.30197501e-01  3.95230979e-01]\n",
      "  [-1.65433908e+00  2.15662169e+00  8.66988182e-01 ... -9.52663064e-01\n",
      "    3.77895534e-01 -6.35939658e-01]\n",
      "  [-1.03613138e+00  1.10319793e+00  9.54733729e-01 ... -4.89366472e-01\n",
      "   -6.15423441e-01  1.10832691e-01]\n",
      "  ...\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]]\n",
      "\n",
      " [[-2.05148637e-01 -4.93502840e-02 -8.80895555e-01 ...  3.77213567e-01\n",
      "   -5.07076621e-01  6.70946300e-01]\n",
      "  [ 5.14505863e+00 -1.18423009e+00 -1.27744305e+00 ... -1.34773314e+00\n",
      "   -2.14204520e-01 -8.01566601e-01]\n",
      "  [ 4.58320379e+00 -1.39496613e+00 -9.50520039e-01 ... -1.24854469e+00\n",
      "   -2.94163555e-01 -5.82439959e-01]\n",
      "  ...\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]]\n",
      "\n",
      " [[ 1.05144747e-01  1.61994338e-01 -7.86025465e-01 ...  1.75804228e-01\n",
      "   -4.84277785e-01  3.94163072e-01]\n",
      "  [ 5.72231579e+00 -1.11193848e+00 -1.49292898e+00 ... -1.22180104e+00\n",
      "   -1.14472580e+00 -6.64589047e-01]\n",
      "  [ 5.80545807e+00 -1.08172405e+00 -1.37532723e+00 ... -1.19817007e+00\n",
      "   -1.09302378e+00 -6.71185315e-01]\n",
      "  ...\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-8.92353654e-01  2.50635773e-01 -7.50131488e-01 ...  6.15866184e-01\n",
      "   -5.13375640e-01  3.91470701e-01]\n",
      "  [ 5.62323284e+00 -1.42958868e+00 -1.41976738e+00 ... -1.33502841e+00\n",
      "   -9.80697751e-01 -1.24953604e+00]\n",
      "  [ 5.35707569e+00 -1.45752597e+00 -1.33712840e+00 ... -1.27408576e+00\n",
      "   -1.27399302e+00 -7.74317980e-01]\n",
      "  ...\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]]\n",
      "\n",
      " [[ 2.20916748e-01 -1.44569501e-01 -8.57415020e-01 ...  7.40686655e-02\n",
      "   -4.42897171e-01  5.99295855e-01]\n",
      "  [ 5.04085875e+00 -1.15783906e+00 -1.20471013e+00 ... -1.35246551e+00\n",
      "   -1.22593746e-01 -6.91467643e-01]\n",
      "  [ 4.31472874e+00 -1.49033618e+00 -9.12997723e-01 ... -1.28416014e+00\n",
      "   -2.30001196e-01 -3.20528805e-01]\n",
      "  ...\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]]\n",
      "\n",
      " [[ 1.14073843e-01  9.84904543e-03 -8.35665822e-01 ...  1.70811817e-01\n",
      "   -5.13305783e-01  4.72851247e-01]\n",
      "  [-1.68728745e+00  8.63093361e-02 -6.65220261e-01 ...  5.82728624e-01\n",
      "    9.80974495e-01 -6.96743727e-01]\n",
      "  [-1.73667407e+00 -2.14655772e-01 -4.30015206e-01 ...  1.56832695e+00\n",
      "    5.03916562e-01 -9.36782658e-02]\n",
      "  ...\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]]]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_pred.predictions  [[[ 3.1677932e-01 -4.6127280e-03 -7.3579812e-01 ... -4.0789951e-02\n",
      "   -5.4448515e-01  4.1704860e-01]\n",
      "  [ 5.6801448e+00 -1.1003916e+00 -1.5225046e+00 ... -1.3451903e+00\n",
      "   -1.2318903e+00 -5.8933997e-01]\n",
      "  [ 5.8188624e+00 -1.0218582e+00 -1.3211249e+00 ... -1.2955551e+00\n",
      "   -1.1164609e+00 -6.4532977e-01]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[ 1.6033606e-01 -1.3364698e-02 -8.2973492e-01 ... -1.1389378e-02\n",
      "   -3.4387100e-01  6.4721155e-01]\n",
      "  [ 2.6184402e+00 -4.3222269e-01 -6.1055797e-01 ... -8.2856023e-01\n",
      "    9.8016024e-01 -6.0756844e-01]\n",
      "  [ 3.6591225e+00 -9.8547572e-01 -8.8772887e-01 ... -5.1342851e-01\n",
      "    4.0097770e-01 -4.2366323e-01]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[ 3.8554600e-01 -3.7604079e-02 -7.5833625e-01 ... -6.8216138e-02\n",
      "   -5.0643378e-01  3.9386633e-01]\n",
      "  [ 5.5885921e+00 -1.9012765e+00 -1.0458654e+00 ... -1.0845770e+00\n",
      "   -7.1603364e-01 -8.9996719e-01]\n",
      "  [ 4.4570484e+00 -8.5959297e-01 -8.0984002e-01 ... -1.2845075e+00\n",
      "   -2.9739928e-01 -1.1854812e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-1.5121041e-01  7.3196933e-02 -9.4667262e-01 ...  4.7808030e-01\n",
      "   -5.1844555e-01  5.8537048e-01]\n",
      "  [ 5.9476523e+00 -1.2125818e+00 -1.3928562e+00 ... -1.1430242e+00\n",
      "   -1.3150529e+00 -7.5319010e-01]\n",
      "  [-1.4751965e+00 -2.9083928e-01 -8.6646199e-01 ...  1.4997671e+00\n",
      "    5.8134514e-01 -5.6389540e-01]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[-7.3350482e-02 -2.3425881e-02 -8.3033514e-01 ...  2.1735966e-01\n",
      "   -4.4463420e-01  6.0143858e-01]\n",
      "  [-2.1465926e+00 -1.8077122e-01 -5.1347750e-01 ...  1.0009416e+00\n",
      "    1.0387815e+00 -1.9974475e-01]\n",
      "  [-2.4413381e+00 -1.1932929e+00 -1.2144511e+00 ...  2.0579906e+00\n",
      "    5.0638276e-01  5.4017431e-01]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[ 2.5096735e-01 -7.1627246e-03 -7.5602657e-01 ... -1.9129768e-02\n",
      "   -5.1657873e-01  4.1961351e-01]\n",
      "  [ 5.6543479e+00 -1.1531312e+00 -1.4950274e+00 ... -1.2764766e+00\n",
      "   -1.1650602e+00 -5.9920174e-01]\n",
      "  [ 5.7702222e+00 -1.0887821e+00 -1.3653277e+00 ... -1.2269837e+00\n",
      "   -1.1527280e+00 -6.4939493e-01]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_431004/2717270868.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics_df = metrics_df.append(\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.set_device(1)\n",
    "torch.cuda.empty_cache()\n",
    "metrics_df = metrics_df.append(\n",
    "        fine_tuning_training_on_single_corpus(panx_fr_encoded, num_samples[0]), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /home/raj/.cache/huggingface/datasets/xtreme/PAN-X.fr/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-3fabc88089e55de9.arrow\n",
      "/home/raj/.conda/envs/raj/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/home/raj/.conda/envs/raj/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='96' max='96' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [96/96 00:55, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.681673</td>\n",
       "      <td>0.548734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.877200</td>\n",
       "      <td>0.451839</td>\n",
       "      <td>0.691964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.877200</td>\n",
       "      <td>0.402017</td>\n",
       "      <td>0.741408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_pred.predictions  [[[ 2.08816469e-01 -9.29322839e-03 -7.30782926e-01 ... -4.65216339e-02\n",
      "   -4.62341100e-01  3.93792003e-01]\n",
      "  [-2.80116558e+00  7.19512701e-01  3.74817342e-01 ...  2.15214342e-02\n",
      "    1.32874751e+00  4.48394358e-01]\n",
      "  [-1.55421984e+00  4.43363249e-01  5.05906522e-01 ...  9.55253318e-02\n",
      "   -2.95842141e-02  3.67827058e-01]\n",
      "  ...\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]]\n",
      "\n",
      " [[ 2.00715736e-01 -1.87264606e-01 -8.58405352e-01 ...  1.40981823e-01\n",
      "   -5.34414351e-01  4.54237580e-01]\n",
      "  [ 3.45179319e+00 -1.02363241e+00 -1.38972402e+00 ... -6.42063975e-01\n",
      "   -6.45407438e-01 -5.07023215e-01]\n",
      "  [ 3.01534891e+00 -1.25642467e+00 -1.27049589e+00 ... -5.14604509e-01\n",
      "   -6.31862223e-01 -2.29879737e-01]\n",
      "  ...\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]]\n",
      "\n",
      " [[ 1.95615217e-01  6.85538799e-02 -7.98351645e-01 ...  3.34607288e-02\n",
      "   -5.01936793e-01  3.14560950e-01]\n",
      "  [ 5.70572710e+00 -8.35225224e-01 -1.40981257e+00 ... -8.20257366e-01\n",
      "   -1.18859947e+00 -9.55266476e-01]\n",
      "  [ 5.85946226e+00 -8.61752808e-01 -1.36760759e+00 ... -7.11892843e-01\n",
      "   -1.18577981e+00 -9.92472887e-01]\n",
      "  ...\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-2.32199907e-01  6.77355975e-02 -9.68968749e-01 ...  3.49916369e-01\n",
      "   -5.79032838e-01  3.63662213e-01]\n",
      "  [ 4.62315941e+00 -1.10852075e+00 -1.69555235e+00 ... -5.14678180e-01\n",
      "   -1.25020182e+00 -1.05945396e+00]\n",
      "  [ 4.74825382e+00 -1.14180422e+00 -1.52891457e+00 ... -4.46062028e-01\n",
      "   -1.46580708e+00 -8.58691394e-01]\n",
      "  ...\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]]\n",
      "\n",
      " [[ 3.48655313e-01 -1.84495434e-01 -8.12150300e-01 ... -7.41048157e-03\n",
      "   -4.73782122e-01  4.60677594e-01]\n",
      "  [ 3.78327608e+00 -9.09799695e-01 -1.21124506e+00 ... -7.03023076e-01\n",
      "   -6.05737090e-01 -4.78647172e-01]\n",
      "  [ 3.31189823e+00 -1.14945638e+00 -1.06409168e+00 ... -7.89329648e-01\n",
      "   -6.63180172e-01 -1.99946716e-01]\n",
      "  ...\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]]\n",
      "\n",
      " [[ 2.64990807e-01 -7.05963671e-02 -8.23431194e-01 ...  6.70762658e-02\n",
      "   -5.21288514e-01  3.65186393e-01]\n",
      "  [-4.73391593e-01  8.32097828e-02 -1.04224467e+00 ...  2.68335462e-01\n",
      "    6.37757242e-01 -9.63651359e-01]\n",
      "  [-1.16256726e+00  1.24711215e-01  1.17321342e-01 ...  1.02795160e+00\n",
      "    3.28872383e-01 -5.14136732e-01]\n",
      "  ...\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]]]\n",
      "eval_pred.predictions  [[[-3.67313266e-01  5.89322269e-01 -1.10604718e-01 ... -2.57346421e-01\n",
      "   -5.89002490e-01 -7.14037716e-02]\n",
      "  [-1.55590749e+00  2.21848750e+00  5.06929517e-01 ... -1.27801073e+00\n",
      "    9.35036421e-01 -6.89435244e-01]\n",
      "  [-1.52789354e+00  1.18622828e+00  2.73869896e+00 ... -6.46121621e-01\n",
      "   -5.20351231e-01 -3.78970504e-02]\n",
      "  ...\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]]\n",
      "\n",
      " [[ 2.26113558e-01 -2.44806588e-01 -8.14029813e-01 ...  2.05593258e-01\n",
      "   -6.43264353e-01  4.23540801e-01]\n",
      "  [ 4.63061571e+00 -1.13536656e+00 -1.41924024e+00 ... -1.06920028e+00\n",
      "   -6.92514300e-01 -8.09974432e-01]\n",
      "  [ 4.44131231e+00 -1.61544681e+00 -1.24106443e+00 ... -7.67079711e-01\n",
      "   -8.94878983e-01 -4.31484252e-01]\n",
      "  ...\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]]\n",
      "\n",
      " [[ 2.27088600e-01  3.48024815e-01 -7.30024397e-01 ...  1.27763808e-01\n",
      "   -6.47994518e-01  1.65582538e-01]\n",
      "  [ 6.22891045e+00 -1.15485573e+00 -1.60725582e+00 ... -1.05928171e+00\n",
      "   -1.51368904e+00 -1.13196588e+00]\n",
      "  [ 6.33066845e+00 -1.15975332e+00 -1.59782124e+00 ... -9.72488999e-01\n",
      "   -1.54392219e+00 -1.16571283e+00]\n",
      "  ...\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-6.78305805e-01  3.64878058e-01 -5.13663590e-01 ...  5.66874683e-01\n",
      "   -4.22696978e-01 -4.97879922e-01]\n",
      "  [ 4.92505836e+00 -1.31499135e+00 -1.68606913e+00 ... -8.78571332e-01\n",
      "   -1.22996283e+00 -1.26871562e+00]\n",
      "  [ 4.90465450e+00 -1.21621501e+00 -1.42265534e+00 ... -7.89541841e-01\n",
      "   -1.61196303e+00 -9.95749772e-01]\n",
      "  ...\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]]\n",
      "\n",
      " [[ 3.52237016e-01 -2.38069296e-01 -7.99373865e-01 ... -1.09923631e-03\n",
      "   -5.12921154e-01  4.54734474e-01]\n",
      "  [ 4.74735928e+00 -1.18409383e+00 -1.23902011e+00 ... -1.08678865e+00\n",
      "   -7.07143068e-01 -7.78704464e-01]\n",
      "  [ 4.51026726e+00 -1.52946711e+00 -9.60815847e-01 ... -1.18384600e+00\n",
      "   -7.81741500e-01 -4.78621870e-01]\n",
      "  ...\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]]\n",
      "\n",
      " [[ 2.92565167e-01 -1.31258622e-01 -8.13735008e-01 ...  1.15878955e-01\n",
      "   -5.98354936e-01  2.72340834e-01]\n",
      "  [ 5.48131168e-01  1.61983281e-01 -2.12049866e+00 ... -9.79620218e-01\n",
      "    4.31416184e-01 -1.55982494e+00]\n",
      "  [-4.38885748e-01 -4.87746954e-01 -6.20914340e-01 ...  8.51682544e-01\n",
      "   -1.21558458e-01 -9.91503358e-01]\n",
      "  ...\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]]]\n",
      "eval_pred.predictions  [[[-1.5021767e-01  6.2163633e-01 -1.8344966e-01 ... -2.8485131e-01\n",
      "   -6.4545572e-01 -7.5215891e-02]\n",
      "  [-1.1816053e+00  3.1796858e+00  3.4417748e-01 ... -1.7355568e+00\n",
      "    8.8026088e-01 -1.1363710e+00]\n",
      "  [-1.3469007e+00  1.6763121e+00  3.1704674e+00 ... -1.0738388e+00\n",
      "   -7.1383506e-01 -1.9422087e-01]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[ 2.2012849e-01 -2.7855182e-01 -8.0764359e-01 ...  2.6492405e-01\n",
      "   -6.6247278e-01  4.3324554e-01]\n",
      "  [ 5.7985764e+00 -1.1921965e+00 -1.2508967e+00 ... -1.3453361e+00\n",
      "   -6.9494647e-01 -1.2953296e+00]\n",
      "  [ 4.5923572e+00 -1.7805512e+00 -1.1234388e+00 ... -5.7261264e-01\n",
      "   -1.1060266e+00 -2.4851203e-01]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[ 2.2011301e-01  3.2073048e-01 -7.4278247e-01 ...  1.7800315e-01\n",
      "   -6.8195748e-01  1.3513660e-01]\n",
      "  [ 6.3746901e+00 -1.1333421e+00 -1.5199722e+00 ... -1.0297028e+00\n",
      "   -1.6210229e+00 -1.3501507e+00]\n",
      "  [ 6.4421186e+00 -1.1378487e+00 -1.5052109e+00 ... -9.2974490e-01\n",
      "   -1.6424496e+00 -1.3886676e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-2.9118034e-01  2.0003688e-01 -8.8122731e-01 ...  6.4156926e-01\n",
      "   -8.0518925e-01 -1.3517702e-01]\n",
      "  [ 5.3511314e+00 -1.4157951e+00 -1.7235729e+00 ... -8.3688998e-01\n",
      "   -1.4133861e+00 -1.7562188e+00]\n",
      "  [ 4.9582443e+00 -1.4014291e+00 -1.4644334e+00 ... -6.7194438e-01\n",
      "   -1.8444393e+00 -1.5367330e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[ 3.5281366e-01 -2.4937817e-01 -7.9960239e-01 ... -1.2831256e-02\n",
      "   -4.9536681e-01  4.8661464e-01]\n",
      "  [ 5.4826517e+00 -1.2236317e+00 -1.1364667e+00 ... -1.3176582e+00\n",
      "   -6.8625724e-01 -1.1453981e+00]\n",
      "  [ 4.8757629e+00 -1.5131421e+00 -7.7056909e-01 ... -1.3560588e+00\n",
      "   -7.2353923e-01 -7.4215984e-01]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[ 2.7042240e-01 -1.4366838e-01 -8.2424808e-01 ...  1.6700459e-01\n",
      "   -6.2447798e-01  2.5370836e-01]\n",
      "  [ 2.5447750e-01  2.4780554e-01 -1.9995601e+00 ... -9.8174024e-01\n",
      "    5.7924652e-01 -1.9530103e+00]\n",
      "  [-4.6409580e-01 -5.7783508e-01 -6.6158509e-01 ...  9.8093486e-01\n",
      "   -1.7330721e-01 -1.0556782e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_pred.predictions  [[[ 3.67272228e-01  8.01113099e-02 -6.30275130e-01 ... -5.58186285e-02\n",
      "   -6.30407810e-01  2.64386326e-01]\n",
      "  [ 6.36451626e+00 -1.07153118e+00 -1.68458176e+00 ... -1.18270981e+00\n",
      "   -1.56772077e+00 -1.29022837e+00]\n",
      "  [ 6.53950453e+00 -1.07378149e+00 -1.60188353e+00 ... -1.10739028e+00\n",
      "   -1.53403223e+00 -1.29192877e+00]\n",
      "  ...\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]]\n",
      "\n",
      " [[-1.59568563e-01  1.09893310e+00 -3.59372616e-01 ... -8.52521434e-02\n",
      "    1.03261426e-01 -8.93157482e-01]\n",
      "  [ 5.27570820e+00 -6.01450324e-01 -1.44947612e+00 ... -1.24375510e+00\n",
      "   -1.17793910e-01 -2.23452234e+00]\n",
      "  [ 5.00690603e+00 -1.12902403e+00 -9.78382885e-01 ... -6.77213311e-01\n",
      "   -7.58381248e-01 -1.64560485e+00]\n",
      "  ...\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]]\n",
      "\n",
      " [[ 2.39817649e-01  6.09851003e-01 -3.85060072e-01 ... -1.44730061e-01\n",
      "   -7.47148812e-01  7.39428273e-04]\n",
      "  [ 6.06326246e+00 -1.72975647e+00 -1.03515899e+00 ... -9.22923923e-01\n",
      "   -1.41072750e+00 -1.20983028e+00]\n",
      "  [ 4.59297419e+00  1.12000033e-01 -6.23860002e-01 ... -1.67901695e+00\n",
      "   -5.09589553e-01 -2.22271562e+00]\n",
      "  ...\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 1.78974792e-01 -2.34966412e-01 -8.80810976e-01 ...  4.18571025e-01\n",
      "   -7.16763735e-01  3.32189858e-01]\n",
      "  [ 5.82138252e+00 -1.20635712e+00 -1.61235654e+00 ... -8.21248770e-01\n",
      "   -1.74498200e+00 -9.11330581e-01]\n",
      "  [-5.19636750e-01 -2.26549715e-01 -2.06806779e+00 ... -1.48067906e-01\n",
      "    1.75288618e-01 -1.62771666e+00]\n",
      "  ...\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]]\n",
      "\n",
      " [[-2.89115161e-02 -1.73255488e-01 -8.47574115e-01 ...  4.86088425e-01\n",
      "   -7.27290869e-01  3.01397771e-01]\n",
      "  [-1.19091690e+00  1.23267025e-01 -1.47051215e+00 ... -2.52348214e-01\n",
      "    7.51942217e-01 -1.69878411e+00]\n",
      "  [-9.38472152e-01 -1.19311488e+00 -1.25007868e+00 ...  1.61603081e+00\n",
      "   -6.70678258e-01 -8.55356455e-01]\n",
      "  ...\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]]\n",
      "\n",
      " [[ 2.70274729e-01  2.28015229e-01 -5.63192189e-01 ... -7.42698312e-02\n",
      "   -6.41917527e-01  1.84262097e-01]\n",
      "  [ 6.45875597e+00 -1.11111093e+00 -1.63058221e+00 ... -1.16843736e+00\n",
      "   -1.59123600e+00 -1.35299635e+00]\n",
      "  [ 6.56379175e+00 -1.13292837e+00 -1.57340467e+00 ... -1.10400140e+00\n",
      "   -1.60444200e+00 -1.33016467e+00]\n",
      "  ...\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_431004/2724915076.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics_df = metrics_df.append(\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "# torch.cuda.set_device(0)\n",
    "torch.cuda.empty_cache()\n",
    "metrics_df = metrics_df.append(\n",
    "        fine_tuning_training_on_single_corpus(panx_fr_encoded, num_samples[1]), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /home/raj/.cache/huggingface/datasets/xtreme/PAN-X.fr/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-3fabc88089e55de9.arrow\n",
      "/home/raj/.conda/envs/raj/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/home/raj/.conda/envs/raj/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='189' max='189' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [189/189 01:26, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.389984</td>\n",
       "      <td>0.743560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.572000</td>\n",
       "      <td>0.349909</td>\n",
       "      <td>0.780600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.572000</td>\n",
       "      <td>0.333345</td>\n",
       "      <td>0.803063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_pred.predictions  [[[ 4.05264050e-01 -9.03697312e-02 -6.90823376e-01 ... -1.08518474e-01\n",
      "   -4.74774182e-01  4.81048942e-01]\n",
      "  [-5.35474300e-01  1.08347261e+00 -2.68329620e+00 ... -1.62090969e+00\n",
      "    3.87684917e+00 -8.29831958e-01]\n",
      "  [-8.82431865e-01 -4.52016741e-01  7.62543261e-01 ...  2.03760892e-01\n",
      "    5.22093534e-01  1.68651414e+00]\n",
      "  ...\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]]\n",
      "\n",
      " [[ 3.92032623e-01 -2.52906978e-01 -7.20228732e-01 ...  8.02576244e-02\n",
      "   -5.82225204e-01  4.90964651e-01]\n",
      "  [ 5.19368267e+00 -6.24701262e-01 -1.53648794e+00 ... -1.10754418e+00\n",
      "    3.09892476e-01 -1.76136339e+00]\n",
      "  [ 5.24170399e+00 -1.50847578e+00 -1.38282037e+00 ... -7.30929732e-01\n",
      "   -2.17041120e-01 -8.13907743e-01]\n",
      "  ...\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]]\n",
      "\n",
      " [[ 3.91199797e-01 -6.42357320e-02 -6.64761901e-01 ...  3.31492424e-02\n",
      "   -6.36110723e-01  3.44161212e-01]\n",
      "  [ 6.08256674e+00 -9.69648838e-01 -1.57038426e+00 ... -8.20433080e-01\n",
      "   -6.03694797e-01 -1.51949191e+00]\n",
      "  [ 5.92078972e+00 -9.38025475e-01 -1.51311803e+00 ... -6.49251580e-01\n",
      "   -6.83211088e-01 -1.45586276e+00]\n",
      "  ...\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 4.37424898e-01 -1.14847243e-01 -7.58995533e-01 ... -5.16407900e-02\n",
      "   -5.82975090e-01  3.41905177e-01]\n",
      "  [ 5.98830509e+00 -1.12346971e+00 -1.78412330e+00 ... -8.78505111e-01\n",
      "   -3.46827984e-01 -1.86877704e+00]\n",
      "  [ 5.73784542e+00 -1.11106896e+00 -1.32404411e+00 ... -7.09485054e-01\n",
      "   -7.54343033e-01 -1.60055447e+00]\n",
      "  ...\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]]\n",
      "\n",
      " [[ 4.26535249e-01 -2.09708586e-01 -7.35255718e-01 ... -1.68826282e-02\n",
      "   -5.31301796e-01  4.68082190e-01]\n",
      "  [ 5.18793678e+00 -5.69251597e-01 -1.51356840e+00 ... -1.10795140e+00\n",
      "    2.31805831e-01 -1.80894804e+00]\n",
      "  [ 4.81682301e+00 -1.57869530e+00 -1.33283591e+00 ... -5.67839205e-01\n",
      "   -5.12412429e-01 -4.57408249e-01]\n",
      "  ...\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]]\n",
      "\n",
      " [[ 4.45295274e-01 -1.58762544e-01 -7.51358509e-01 ... -3.84224728e-02\n",
      "   -5.11607587e-01  3.96029890e-01]\n",
      "  [-1.76117092e-01  7.07560182e-01 -2.80072808e+00 ... -9.59691286e-01\n",
      "    1.46089876e+00 -2.18766785e+00]\n",
      "  [-7.74035573e-01 -5.62514126e-01 -5.38918614e-01 ...  1.86064005e+00\n",
      "   -6.57682896e-01 -6.15900636e-01]\n",
      "  ...\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]]]\n",
      "eval_pred.predictions  [[[ 3.7334138e-01 -1.7016180e-02 -6.3194996e-01 ... -8.1196249e-02\n",
      "   -5.7720459e-01  3.4926522e-01]\n",
      "  [-1.6392157e+00  3.2913611e+00 -1.9180906e+00 ... -1.8503959e+00\n",
      "    3.1678288e+00 -2.1891966e+00]\n",
      "  [-1.1806121e+00  1.3133349e+00  2.0335498e+00 ... -5.8774114e-01\n",
      "   -7.7557129e-01  4.5508942e-01]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[ 2.6814535e-01 -4.2729941e-01 -7.7873063e-01 ...  4.7835794e-01\n",
      "   -7.0781952e-01  6.1530942e-01]\n",
      "  [ 5.8957062e+00 -8.3135515e-01 -1.9187597e+00 ... -7.3671937e-01\n",
      "   -1.9774896e-01 -1.8066142e+00]\n",
      "  [ 5.6441259e+00 -1.2578716e+00 -1.5709493e+00 ... -6.4556551e-01\n",
      "   -3.5228801e-01 -1.3946145e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[ 3.1304863e-01 -3.9353147e-03 -6.0143459e-01 ...  1.8120283e-01\n",
      "   -7.5717926e-01  2.3149849e-01]\n",
      "  [ 6.2807498e+00 -1.0529678e+00 -1.9556729e+00 ... -3.5251632e-01\n",
      "   -1.2997673e+00 -1.8273094e+00]\n",
      "  [ 6.2306924e+00 -1.0349510e+00 -1.9906440e+00 ... -2.5082433e-01\n",
      "   -1.3812084e+00 -1.8221027e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 3.6274144e-01 -1.2426207e-01 -8.3144164e-01 ...  1.0181942e-01\n",
      "   -6.6046453e-01  2.7598476e-01]\n",
      "  [ 6.1479321e+00 -1.1469872e+00 -2.2576756e+00 ... -5.1440918e-01\n",
      "   -8.2003081e-01 -2.4393215e+00]\n",
      "  [ 6.0631046e+00 -1.3158257e+00 -1.8928864e+00 ... -2.9572442e-01\n",
      "   -1.3247583e+00 -2.0540824e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[ 3.3798566e-01 -3.2991076e-01 -8.1833231e-01 ...  1.3970283e-01\n",
      "   -5.4243565e-01  6.1406571e-01]\n",
      "  [ 5.7716160e+00 -6.9205147e-01 -1.8490541e+00 ... -8.7952453e-01\n",
      "   -1.4712361e-01 -2.0834672e+00]\n",
      "  [ 5.3784170e+00 -1.3819197e+00 -1.4256520e+00 ... -6.9255614e-01\n",
      "   -4.9987626e-01 -1.3892777e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[ 4.5130289e-01 -1.8999973e-01 -7.7998716e-01 ...  2.3787774e-02\n",
      "   -5.3807890e-01  3.4794772e-01]\n",
      "  [-2.8836566e-01  9.8260278e-01 -2.7378526e+00 ... -1.1132309e+00\n",
      "    1.2882146e+00 -2.8678291e+00]\n",
      "  [-3.2024541e-01 -1.0622302e+00 -8.6912870e-01 ...  2.7073572e+00\n",
      "   -1.1620615e+00 -1.2681772e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]]\n",
      "eval_pred.predictions  [[[ 3.6451930e-01  3.4432411e-03 -4.9289089e-01 ... -7.3377348e-02\n",
      "   -6.6852552e-01  2.8744602e-01]\n",
      "  [-1.8234167e+00  5.7630596e+00 -9.6664262e-01 ... -1.8604007e+00\n",
      "    1.2595079e+00 -2.6952276e+00]\n",
      "  [-1.6532309e+00  2.3899999e+00  3.8622322e+00 ... -5.0677472e-01\n",
      "   -1.8312392e+00 -6.8782544e-01]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[ 1.9469969e-01 -4.4287312e-01 -7.0496947e-01 ...  6.0382175e-01\n",
      "   -7.9833448e-01  5.4674202e-01]\n",
      "  [ 6.0847063e+00 -7.5102568e-01 -1.8689365e+00 ... -9.8812532e-01\n",
      "   -2.5469893e-01 -2.0933115e+00]\n",
      "  [ 5.8069639e+00 -1.2230932e+00 -1.5552572e+00 ... -8.6606312e-01\n",
      "   -4.3902704e-01 -1.6378031e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[ 3.1996632e-01 -8.6329080e-02 -6.5022910e-01 ...  2.3958537e-01\n",
      "   -7.7410692e-01  2.0950860e-01]\n",
      "  [ 6.5500107e+00 -1.0632664e+00 -1.9967794e+00 ... -5.1029664e-01\n",
      "   -1.4084930e+00 -1.9419957e+00]\n",
      "  [ 6.4630904e+00 -1.0416329e+00 -2.0137026e+00 ... -4.0609011e-01\n",
      "   -1.4818933e+00 -1.9447917e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 4.1690585e-01 -1.3093488e-01 -7.8979725e-01 ...  3.1697772e-02\n",
      "   -6.3275510e-01  2.6564553e-01]\n",
      "  [ 6.3492670e+00 -1.0739642e+00 -2.2346866e+00 ... -6.3105714e-01\n",
      "   -8.6040270e-01 -2.4917531e+00]\n",
      "  [ 6.3076601e+00 -1.2989671e+00 -1.6932524e+00 ... -2.8773290e-01\n",
      "   -1.4166762e+00 -2.0874104e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[ 3.0094695e-01 -3.4579492e-01 -7.5260955e-01 ...  1.6483608e-01\n",
      "   -5.7104254e-01  6.3381255e-01]\n",
      "  [ 5.9161134e+00 -6.3054520e-01 -1.8127828e+00 ... -1.0000914e+00\n",
      "   -2.7579919e-01 -2.2578487e+00]\n",
      "  [ 5.5411363e+00 -1.3418205e+00 -1.4315653e+00 ... -8.7864244e-01\n",
      "   -6.2330240e-01 -1.5802209e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[ 4.4020236e-01 -1.8569325e-01 -7.6717460e-01 ...  2.3536630e-02\n",
      "   -5.4633540e-01  3.3545959e-01]\n",
      "  [-3.1018040e-01  1.2891233e+00 -2.8432255e+00 ... -1.3191854e+00\n",
      "    1.1894143e+00 -3.0507889e+00]\n",
      "  [-3.0121338e-01 -6.0806978e-01 -1.1207643e+00 ...  1.8816891e+00\n",
      "   -1.0514722e+00 -1.6916504e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_pred.predictions  [[[ 3.7481770e-01  9.8007381e-02 -4.3337867e-01 ... -6.1456915e-02\n",
      "   -7.4363846e-01  1.8545675e-01]\n",
      "  [ 6.6604972e+00 -1.0748755e+00 -1.8846713e+00 ... -6.8268001e-01\n",
      "   -1.2586501e+00 -2.0332761e+00]\n",
      "  [ 6.6410232e+00 -1.0156718e+00 -1.7448851e+00 ... -5.4691845e-01\n",
      "   -1.3583319e+00 -1.9337374e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[ 4.8791084e-01 -1.8648674e-01 -8.2945466e-01 ... -1.4718354e-01\n",
      "   -3.7754214e-01  4.4489968e-01]\n",
      "  [ 4.5765529e+00 -3.6683765e-01 -2.6688149e+00 ... -1.3669901e+00\n",
      "    1.6289470e+00 -2.5489149e+00]\n",
      "  [ 5.4194140e+00 -1.5458709e+00 -1.7509220e+00 ... -4.4962296e-01\n",
      "   -1.7718951e-01 -1.6788481e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[ 3.3007675e-01  2.0994623e-01 -3.2446307e-01 ... -7.4874125e-02\n",
      "   -8.5273153e-01  1.4134568e-01]\n",
      "  [ 6.2908893e+00 -1.5493321e+00 -1.0484700e+00 ... -2.4089578e-01\n",
      "   -1.2684894e+00 -1.7751855e+00]\n",
      "  [ 5.9275136e+00 -5.8606887e-01 -1.2801892e+00 ... -7.2442436e-01\n",
      "   -9.6510017e-01 -2.2228663e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 3.0617186e-01 -3.1715697e-01 -8.1552655e-01 ...  4.5328042e-01\n",
      "   -7.1510273e-01  3.9256945e-01]\n",
      "  [ 6.3497534e+00 -1.0201082e+00 -1.9953016e+00 ... -3.6221620e-01\n",
      "   -1.5937810e+00 -1.8253061e+00]\n",
      "  [-1.1413063e+00  3.5664484e-01 -2.4926589e+00 ... -7.0541370e-01\n",
      "    1.1146426e+00 -2.6987064e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[ 3.6578032e-01 -2.5042626e-01 -7.2419316e-01 ...  2.5960234e-01\n",
      "   -6.7050076e-01  3.4001818e-01]\n",
      "  [-1.3989003e+00  1.1475838e+00 -1.9494852e+00 ... -4.8602644e-01\n",
      "    1.0035021e+00 -2.6671448e+00]\n",
      "  [-3.9980000e-01 -2.1175158e+00 -1.0939828e+00 ...  3.6002116e+00\n",
      "   -1.6910769e+00 -7.4511194e-01]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[ 3.6295560e-01  8.7549940e-02 -4.5910549e-01 ... -7.6287977e-02\n",
      "   -7.1817029e-01  2.0087214e-01]\n",
      "  [ 6.7472239e+00 -1.1018559e+00 -1.8362468e+00 ... -7.1749002e-01\n",
      "   -1.3805954e+00 -2.0055637e+00]\n",
      "  [ 6.6874824e+00 -1.0495020e+00 -1.7679169e+00 ... -5.9052277e-01\n",
      "   -1.4854908e+00 -1.9367182e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_431004/2892426431.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics_df = metrics_df.append(\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "# torch.cuda.set_device(0)\n",
    "torch.cuda.empty_cache()\n",
    "metrics_df = metrics_df.append(\n",
    "        fine_tuning_training_on_single_corpus(panx_fr_encoded, num_samples[2]), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /home/raj/.cache/huggingface/datasets/xtreme/PAN-X.fr/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-3fabc88089e55de9.arrow\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 13/375 00:03 < 01:58, 3.07 it/s, Epoch 0.10/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 734.00 MiB (GPU 0; 11.76 GiB total capacity; 8.32 GiB already allocated; 594.81 MiB free; 10.29 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[87], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mempty_cache()\n\u001b[1;32m      6\u001b[0m batch_size \u001b[39m=\u001b[39m \u001b[39m8\u001b[39m\n\u001b[1;32m      7\u001b[0m metrics_df \u001b[39m=\u001b[39m metrics_df\u001b[39m.\u001b[39mappend(\n\u001b[0;32m----> 8\u001b[0m         fine_tuning_training_on_single_corpus(panx_fr_encoded, num_samples[\u001b[39m3\u001b[39;49m]), ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[66], line 35\u001b[0m, in \u001b[0;36mfine_tuning_training_on_single_corpus\u001b[0;34m(dataset, num_samples)\u001b[0m\n\u001b[1;32m     30\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(model_init\u001b[39m=\u001b[39mmodel_init, args\u001b[39m=\u001b[39mtraining_args,\n\u001b[1;32m     31\u001b[0m     data_collator\u001b[39m=\u001b[39mdata_collator, compute_metrics\u001b[39m=\u001b[39mcompute_metrics,\n\u001b[1;32m     32\u001b[0m     train_dataset\u001b[39m=\u001b[39mtrain_ds, eval_dataset\u001b[39m=\u001b[39mvalid_ds, tokenizer\u001b[39m=\u001b[39mxlmr_tokenizer)\n\u001b[1;32m     34\u001b[0m \u001b[39m# Train the model.\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n\u001b[1;32m     37\u001b[0m \u001b[39m# If the training arguments specify to push the model to the HuggingFace model hub, do so with a commit message.\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[39mif\u001b[39;00m training_args\u001b[39m.\u001b[39mpush_to_hub:\n",
      "File \u001b[0;32m~/.conda/envs/raj/lib/python3.11/site-packages/transformers/trainer.py:1645\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1640\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[1;32m   1642\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1643\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1644\u001b[0m )\n\u001b[0;32m-> 1645\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1646\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1647\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1648\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1649\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1650\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/raj/lib/python3.11/site-packages/transformers/trainer.py:1929\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1926\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_step_begin(args, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n\u001b[1;32m   1928\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator\u001b[39m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 1929\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(model, inputs)\n\u001b[1;32m   1931\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   1932\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1933\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1934\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1935\u001b[0m ):\n\u001b[1;32m   1936\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1937\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/.conda/envs/raj/lib/python3.11/site-packages/transformers/trainer.py:2761\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2759\u001b[0m         scaled_loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m   2760\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2761\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maccelerator\u001b[39m.\u001b[39;49mbackward(loss)\n\u001b[1;32m   2763\u001b[0m \u001b[39mreturn\u001b[39;00m loss\u001b[39m.\u001b[39mdetach() \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mgradient_accumulation_steps\n",
      "File \u001b[0;32m~/.conda/envs/raj/lib/python3.11/site-packages/accelerate/accelerator.py:1821\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   1819\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscaler\u001b[39m.\u001b[39mscale(loss)\u001b[39m.\u001b[39mbackward(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1820\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1821\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/raj/lib/python3.11/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/raj/lib/python3.11/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/.conda/envs/raj/lib/python3.11/site-packages/torch/autograd/function.py:274\u001b[0m, in \u001b[0;36mBackwardCFunction.apply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mImplementing both \u001b[39m\u001b[39m'\u001b[39m\u001b[39mbackward\u001b[39m\u001b[39m'\u001b[39m\u001b[39m and \u001b[39m\u001b[39m'\u001b[39m\u001b[39mvjp\u001b[39m\u001b[39m'\u001b[39m\u001b[39m for a custom \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    271\u001b[0m                        \u001b[39m\"\u001b[39m\u001b[39mFunction is not allowed. You should only implement one \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    272\u001b[0m                        \u001b[39m\"\u001b[39m\u001b[39mof them.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    273\u001b[0m user_fn \u001b[39m=\u001b[39m vjp_fn \u001b[39mif\u001b[39;00m vjp_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m Function\u001b[39m.\u001b[39mvjp \u001b[39melse\u001b[39;00m backward_fn\n\u001b[0;32m--> 274\u001b[0m \u001b[39mreturn\u001b[39;00m user_fn(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[0;32m~/.conda/envs/raj/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:34\u001b[0m, in \u001b[0;36mBroadcast.backward\u001b[0;34m(ctx, *grad_outputs)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m     33\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbackward\u001b[39m(ctx, \u001b[39m*\u001b[39mgrad_outputs):\n\u001b[0;32m---> 34\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mNone\u001b[39;00m,) \u001b[39m+\u001b[39m ReduceAddCoalesced\u001b[39m.\u001b[39;49mapply(ctx\u001b[39m.\u001b[39;49minput_device, ctx\u001b[39m.\u001b[39;49mnum_inputs, \u001b[39m*\u001b[39;49mgrad_outputs)\n",
      "File \u001b[0;32m~/.conda/envs/raj/lib/python3.11/site-packages/torch/autograd/function.py:506\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    504\u001b[0m     \u001b[39m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    505\u001b[0m     args \u001b[39m=\u001b[39m _functorch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 506\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mapply(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39msetup_context \u001b[39m==\u001b[39m _SingleLevelFunction\u001b[39m.\u001b[39msetup_context:\n\u001b[1;32m    509\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    510\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    511\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    512\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mstaticmethod. For more details, please see \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    513\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/raj/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:45\u001b[0m, in \u001b[0;36mReduceAddCoalesced.forward\u001b[0;34m(ctx, destination, num_inputs, *grads)\u001b[0m\n\u001b[1;32m     41\u001b[0m ctx\u001b[39m.\u001b[39mtarget_gpus \u001b[39m=\u001b[39m [grads[i]\u001b[39m.\u001b[39mget_device() \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(grads), num_inputs)]\n\u001b[1;32m     43\u001b[0m grads_ \u001b[39m=\u001b[39m [grads[i:i \u001b[39m+\u001b[39m num_inputs]\n\u001b[1;32m     44\u001b[0m           \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(grads), num_inputs)]\n\u001b[0;32m---> 45\u001b[0m \u001b[39mreturn\u001b[39;00m comm\u001b[39m.\u001b[39;49mreduce_add_coalesced(grads_, destination)\n",
      "File \u001b[0;32m~/.conda/envs/raj/lib/python3.11/site-packages/torch/nn/parallel/comm.py:143\u001b[0m, in \u001b[0;36mreduce_add_coalesced\u001b[0;34m(inputs, destination, buffer_size)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[39mfor\u001b[39;00m chunks \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mitrs):\n\u001b[1;32m    142\u001b[0m     flat_tensors \u001b[39m=\u001b[39m [_flatten_dense_tensors(chunk) \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m chunks]  \u001b[39m# (num_gpus,)\u001b[39;00m\n\u001b[0;32m--> 143\u001b[0m     flat_result \u001b[39m=\u001b[39m reduce_add(flat_tensors, destination)\n\u001b[1;32m    144\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m _unflatten_dense_tensors(flat_result, chunks[\u001b[39m0\u001b[39m]):\n\u001b[1;32m    145\u001b[0m         \u001b[39m# The unflattened tensors do not share storage, and we don't expose\u001b[39;00m\n\u001b[1;32m    146\u001b[0m         \u001b[39m# base flat tensor anyways, so give them different version counters.\u001b[39;00m\n\u001b[1;32m    147\u001b[0m         \u001b[39m# See NOTE [ Version Counter in comm.*_coalesced ]\u001b[39;00m\n\u001b[1;32m    148\u001b[0m         output\u001b[39m.\u001b[39mappend(t\u001b[39m.\u001b[39mdata)\n",
      "File \u001b[0;32m~/.conda/envs/raj/lib/python3.11/site-packages/torch/nn/parallel/comm.py:95\u001b[0m, in \u001b[0;36mreduce_add\u001b[0;34m(inputs, destination)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[39mreturn\u001b[39;00m inputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m     94\u001b[0m \u001b[39mif\u001b[39;00m nccl\u001b[39m.\u001b[39mis_available(inputs):\n\u001b[0;32m---> 95\u001b[0m     result \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mempty_like(inputs[root_index])\n\u001b[1;32m     96\u001b[0m     nccl\u001b[39m.\u001b[39mreduce(inputs, output\u001b[39m=\u001b[39mresult, root\u001b[39m=\u001b[39mroot_index)\n\u001b[1;32m     97\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 734.00 MiB (GPU 0; 11.76 GiB total capacity; 8.32 GiB already allocated; 594.81 MiB free; 10.29 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "torch.cuda.set_device(1)\n",
    "torch.cuda.empty_cache()\n",
    "batch_size = 8\n",
    "metrics_df = metrics_df.append(\n",
    "        fine_tuning_training_on_single_corpus(panx_fr_encoded, num_samples[3]), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.axhline(f1_scores[\"de\"][\"fr\"], ls=\"--\", color=\"r\")\n",
    "metrics_df.set_index(\"num_samples\").plot(ax=ax)\n",
    "plt.legend([\"Zero-shot from de\", \"Fine-tuned on fr\"], loc=\"lower right\")\n",
    "plt.ylim((0, 1))\n",
    "plt.xlabel(\"Number of Training Samples\")\n",
    "plt.ylabel(\"F1 Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import concatenate_datasets\n",
    "\n",
    "def concatenate_splits(corpora):\n",
    "    \"\"\"\n",
    "    Function to concatenate multiple corpora together, and shuffle the result.\n",
    "\n",
    "    Parameters:\n",
    "    corpora (list): A list of corpora, where each corpus is an instance of DatasetDict from the HuggingFace `datasets` library.\n",
    "                     Each DatasetDict should contain the same train/validation/test splits.\n",
    "\n",
    "    Returns:\n",
    "    multi_corpus (DatasetDict): A DatasetDict containing the concatenated and shuffled datasets.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize an empty DatasetDict to hold the concatenated datasets.\n",
    "    multi_corpus = DatasetDict()\n",
    "\n",
    "    # For each split (train, validation, test) in the first corpus in the list...\n",
    "    for train_val_test_split in corpora[0].keys():\n",
    "\n",
    "        # Concatenate the corresponding split from all corpora in the list.\n",
    "        # The `concatenate_datasets` function from HuggingFace `datasets` is used here.\n",
    "        # The concatenated dataset is then shuffled with a fixed seed for reproducibility.\n",
    "        multi_corpus[train_val_test_split] = concatenate_datasets(\n",
    "            [corpus[train_val_test_split] for corpus in corpora]).shuffle(seed=42)\n",
    "\n",
    "    # Return the concatenated and shuffled DatasetDict.\n",
    "    return multi_corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "panx_de_fr_concatenated_encoded = concatenate_splits([panx_de_encoded, panx_fr_encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1611' max='1611' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1611/1611 10:45, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.189590</td>\n",
       "      <td>0.812249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.164295</td>\n",
       "      <td>0.848188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.163690</td>\n",
       "      <td>0.855953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_pred.predictions  [[[   3.0771189    -0.598589     -0.7140426  ...   -0.7052609\n",
      "      0.5747626    -1.3551121 ]\n",
      "  [   7.884901     -1.8699633    -1.517168   ...   -1.107081\n",
      "     -1.0663092    -1.7805163 ]\n",
      "  [   7.9407663    -2.0293598    -1.4216915  ...   -0.8906573\n",
      "     -1.2543356    -1.5873696 ]\n",
      "  ...\n",
      "  [-100.         -100.         -100.         ... -100.\n",
      "   -100.         -100.        ]\n",
      "  [-100.         -100.         -100.         ... -100.\n",
      "   -100.         -100.        ]\n",
      "  [-100.         -100.         -100.         ... -100.\n",
      "   -100.         -100.        ]]\n",
      "\n",
      " [[   3.6607487    -1.6986357    -1.8648319  ...   -1.4140469\n",
      "      1.4351432     0.5210339 ]\n",
      "  [   6.302573     -1.5369805    -2.2299025  ...   -1.7758459\n",
      "      0.8665931    -1.9704179 ]\n",
      "  [   7.233485     -2.166623     -2.2204573  ...   -1.0241097\n",
      "     -0.53265417   -1.4169366 ]\n",
      "  ...\n",
      "  [-100.         -100.         -100.         ... -100.\n",
      "   -100.         -100.        ]\n",
      "  [-100.         -100.         -100.         ... -100.\n",
      "   -100.         -100.        ]\n",
      "  [-100.         -100.         -100.         ... -100.\n",
      "   -100.         -100.        ]]\n",
      "\n",
      " [[   4.44768      -0.61160624   -1.2399724  ...   -1.0308112\n",
      "     -0.14668448   -1.5565509 ]\n",
      "  [   7.7817893    -2.2297826    -0.9427746  ...   -1.0434142\n",
      "     -1.4826193    -1.323323  ]\n",
      "  [   7.8188014    -2.250324     -0.9769717  ...   -1.078309\n",
      "     -1.3704172    -1.4630588 ]\n",
      "  ...\n",
      "  [-100.         -100.         -100.         ... -100.\n",
      "   -100.         -100.        ]\n",
      "  [-100.         -100.         -100.         ... -100.\n",
      "   -100.         -100.        ]\n",
      "  [-100.         -100.         -100.         ... -100.\n",
      "   -100.         -100.        ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[   2.1910262    -0.37829906   -0.2066363  ...   -0.49745142\n",
      "      0.44057366   -1.0400131 ]\n",
      "  [   7.7311144    -1.7897136    -1.3036573  ...   -0.9953092\n",
      "     -1.0755428    -1.702616  ]\n",
      "  [   7.8976307    -2.1305516    -1.0673937  ...   -0.6445799\n",
      "     -1.4593999    -1.3648449 ]\n",
      "  ...\n",
      "  [-100.         -100.         -100.         ... -100.\n",
      "   -100.         -100.        ]\n",
      "  [-100.         -100.         -100.         ... -100.\n",
      "   -100.         -100.        ]\n",
      "  [-100.         -100.         -100.         ... -100.\n",
      "   -100.         -100.        ]]\n",
      "\n",
      " [[   2.0811577    -0.80409294   -0.5391484  ...   -0.6191152\n",
      "      0.99198496   -0.3500632 ]\n",
      "  [   7.487931     -1.9302884    -1.276559   ...   -1.1080952\n",
      "     -0.775175     -1.5858079 ]\n",
      "  [   7.7723823    -2.0709488    -1.2679708  ...   -0.8496532\n",
      "     -0.9943802    -1.356892  ]\n",
      "  ...\n",
      "  [-100.         -100.         -100.         ... -100.\n",
      "   -100.         -100.        ]\n",
      "  [-100.         -100.         -100.         ... -100.\n",
      "   -100.         -100.        ]\n",
      "  [-100.         -100.         -100.         ... -100.\n",
      "   -100.         -100.        ]]\n",
      "\n",
      " [[   2.1887932    -0.5149378    -0.40791023 ...   -0.6694015\n",
      "      0.773648     -0.89206415]\n",
      "  [   8.1166935    -1.835441     -1.2785356  ...   -1.0038007\n",
      "     -1.2784435    -1.5388004 ]\n",
      "  [   8.20966      -1.953178     -1.2061288  ...   -0.79457\n",
      "     -1.4401706    -1.3043036 ]\n",
      "  ...\n",
      "  [-100.         -100.         -100.         ... -100.\n",
      "   -100.         -100.        ]\n",
      "  [-100.         -100.         -100.         ... -100.\n",
      "   -100.         -100.        ]\n",
      "  [-100.         -100.         -100.         ... -100.\n",
      "   -100.         -100.        ]]]\n",
      "eval_pred.predictions  [[[   5.22886      -0.42517424   -2.1962483  ...   -1.3370659\n",
      "      0.71848375   -2.2890835 ]\n",
      "  [   8.1987915    -1.3272525    -2.5227184  ...   -1.5634336\n",
      "     -1.004956     -2.8055089 ]\n",
      "  [   8.478624     -1.712775     -2.161768   ...   -1.0735824\n",
      "     -1.5949037    -2.1997614 ]\n",
      "  ...\n",
      "  [-100.         -100.         -100.         ... -100.\n",
      "   -100.         -100.        ]\n",
      "  [-100.         -100.         -100.         ... -100.\n",
      "   -100.         -100.        ]\n",
      "  [-100.         -100.         -100.         ... -100.\n",
      "   -100.         -100.        ]]\n",
      "\n",
      " [[   2.9664474    -1.1870738    -2.2641444  ...   -1.311718\n",
      "      0.98180884    0.7319022 ]\n",
      "  [   6.760043     -0.8898226    -2.5394835  ...   -1.9551799\n",
      "     -0.13550587   -2.8240528 ]\n",
      "  [   7.0900044    -1.3173023    -2.4505095  ...   -1.3261635\n",
      "     -0.70217675   -2.5389202 ]\n",
      "  ...\n",
      "  [-100.         -100.         -100.         ... -100.\n",
      "   -100.         -100.        ]\n",
      "  [-100.         -100.         -100.         ... -100.\n",
      "   -100.         -100.        ]\n",
      "  [-100.         -100.         -100.         ... -100.\n",
      "   -100.         -100.        ]]\n",
      "\n",
      " [[   2.9177792     0.1395794    -1.1342471  ...   -0.78095365\n",
      "     -0.45702747   -1.4207499 ]\n",
      "  [   7.6168942    -1.5862672    -1.0946672  ...   -0.99718714\n",
      "     -1.8070787    -2.4053864 ]\n",
      "  [   7.8598742    -1.6536763    -1.1682163  ...   -0.8719029\n",
      "     -1.782714     -2.4438572 ]\n",
      "  ...\n",
      "  [-100.         -100.         -100.         ... -100.\n",
      "   -100.         -100.        ]\n",
      "  [-100.         -100.         -100.         ... -100.\n",
      "   -100.         -100.        ]\n",
      "  [-100.         -100.         -100.         ... -100.\n",
      "   -100.         -100.        ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[   3.1822472    -0.1763252    -0.74827427 ...   -0.9155565\n",
      "      0.4820919    -1.5961221 ]\n",
      "  [   8.481229     -1.3490164    -2.0449634  ...   -1.2836709\n",
      "     -1.3964854    -2.4315605 ]\n",
      "  [   8.613708     -1.6680099    -1.7334263  ...   -0.9233667\n",
      "     -1.7688031    -2.1147964 ]\n",
      "  ...\n",
      "  [-100.         -100.         -100.         ... -100.\n",
      "   -100.         -100.        ]\n",
      "  [-100.         -100.         -100.         ... -100.\n",
      "   -100.         -100.        ]\n",
      "  [-100.         -100.         -100.         ... -100.\n",
      "   -100.         -100.        ]]\n",
      "\n",
      " [[   3.6298747    -0.996045     -1.7537613  ...   -1.5204637\n",
      "      1.6430906    -0.5257775 ]\n",
      "  [   8.661301     -1.6302996    -1.9664761  ...   -1.4443184\n",
      "     -1.2675667    -2.1245904 ]\n",
      "  [   8.750312     -1.681312     -1.985863   ...   -1.16577\n",
      "     -1.340299     -1.9625725 ]\n",
      "  ...\n",
      "  [-100.         -100.         -100.         ... -100.\n",
      "   -100.         -100.        ]\n",
      "  [-100.         -100.         -100.         ... -100.\n",
      "   -100.         -100.        ]\n",
      "  [-100.         -100.         -100.         ... -100.\n",
      "   -100.         -100.        ]]\n",
      "\n",
      " [[   4.7677255    -0.85762167   -2.2383237  ...   -1.6852324\n",
      "      1.3468989    -1.1081675 ]\n",
      "  [   8.747074     -1.529568     -1.927167   ...   -1.17683\n",
      "     -1.6464995    -2.101417  ]\n",
      "  [   8.806272     -1.6084408    -1.8287656  ...   -0.8944056\n",
      "     -1.8248262    -1.7804396 ]\n",
      "  ...\n",
      "  [-100.         -100.         -100.         ... -100.\n",
      "   -100.         -100.        ]\n",
      "  [-100.         -100.         -100.         ... -100.\n",
      "   -100.         -100.        ]\n",
      "  [-100.         -100.         -100.         ... -100.\n",
      "   -100.         -100.        ]]]\n",
      "eval_pred.predictions  [[[ 5.4471006e+00 -7.3161852e-01 -2.4672878e+00 ... -1.2901506e+00\n",
      "    7.2556132e-01 -2.1663070e+00]\n",
      "  [ 8.3460331e+00 -1.2555732e+00 -2.9398847e+00 ... -1.9367969e+00\n",
      "   -6.1432147e-01 -2.8481507e+00]\n",
      "  [ 8.8534632e+00 -1.7988150e+00 -2.4033089e+00 ... -1.3086054e+00\n",
      "   -1.3987459e+00 -2.1091402e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[ 2.6477826e+00 -1.3172548e+00 -2.2670341e+00 ... -1.3082472e+00\n",
      "    1.0733289e+00  1.0975178e+00]\n",
      "  [ 7.4053812e+00 -9.7987425e-01 -2.8679571e+00 ... -2.2273297e+00\n",
      "   -1.2749851e-01 -2.7580540e+00]\n",
      "  [ 7.8733807e+00 -1.5060194e+00 -2.8235836e+00 ... -1.4484649e+00\n",
      "   -7.9984492e-01 -2.4290953e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[ 2.4324768e+00  2.5149889e-04 -1.0470420e+00 ... -6.9645250e-01\n",
      "   -4.1565344e-01 -1.0058969e+00]\n",
      "  [ 8.0385265e+00 -1.6738145e+00 -1.4649681e+00 ... -1.1825336e+00\n",
      "   -1.6020032e+00 -2.3465211e+00]\n",
      "  [ 8.4273815e+00 -1.8623228e+00 -1.5363537e+00 ... -9.6628839e-01\n",
      "   -1.7123423e+00 -2.3014836e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 3.8721447e+00 -3.4119925e-01 -1.0655395e+00 ... -1.1671237e+00\n",
      "    4.7913677e-01 -1.5655311e+00]\n",
      "  [ 8.8236551e+00 -1.3598835e+00 -2.2522295e+00 ... -1.5752250e+00\n",
      "   -1.2057289e+00 -2.3105094e+00]\n",
      "  [ 8.8276920e+00 -1.7715584e+00 -1.8653131e+00 ... -1.0759907e+00\n",
      "   -1.5935880e+00 -1.8925385e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[ 3.9434969e+00 -1.5814995e+00 -2.3124065e+00 ... -1.7222953e+00\n",
      "    2.0721765e+00  3.1088835e-01]\n",
      "  [ 8.7698212e+00 -1.6879079e+00 -2.1822460e+00 ... -1.6675779e+00\n",
      "   -9.4338185e-01 -2.0329845e+00]\n",
      "  [ 8.8929129e+00 -1.8386155e+00 -2.1482279e+00 ... -1.2568363e+00\n",
      "   -1.0818206e+00 -1.7149523e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[ 4.8798704e+00 -1.2007966e+00 -2.4532745e+00 ... -1.8391650e+00\n",
      "    1.5567701e+00 -7.8199542e-01]\n",
      "  [ 9.0391626e+00 -1.6145917e+00 -2.1486802e+00 ... -1.4126346e+00\n",
      "   -1.4748882e+00 -1.9367455e+00]\n",
      "  [ 9.1072941e+00 -1.6928542e+00 -2.1296546e+00 ... -1.1308565e+00\n",
      "   -1.6131555e+00 -1.6572114e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1611, training_loss=0.17946025675531502, metrics={'train_runtime': 645.7978, 'train_samples_per_second': 79.715, 'train_steps_per_second': 2.495, 'total_flos': 1217861247419520.0, 'train_loss': 0.17946025675531502, 'epoch': 3.0})"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "torch.cuda.set_device(1)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "training_args.logging_steps = len(panx_de_fr_concatenated_encoded[\"train\"]) // batch_size\n",
    "# training_args.push_to_hub = True\n",
    "training_args.push_to_hub = False  # PAUL - Changing to False\n",
    "training_args.output_dir = \"xlm-roberta-base-finetuned-panx-de-fr\"\n",
    "\n",
    "trainer = Trainer(model_init=model_init, args=training_args,\n",
    "    data_collator=data_collator, compute_metrics=compute_metrics,\n",
    "    tokenizer=xlmr_tokenizer, train_dataset=panx_de_fr_concatenated_encoded[\"train\"],\n",
    "    eval_dataset=panx_de_fr_concatenated_encoded[\"validation\"])\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8319a03569144765a5c4558dbc7bf079",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12580 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5996c4e2d2314511bd973c8dd938b121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6290 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9e7a531ea614465a46a52051c841bf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6290 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/.conda/envs/raj/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_pred.predictions  [[[ 1.0373670e+00 -2.5196846e+00 -1.2868844e+00 ... -4.7649765e-01\n",
      "    9.8365921e-01  4.6399751e+00]\n",
      "  [ 8.8123932e+00 -1.8669630e+00 -2.3624783e+00 ... -1.3708290e+00\n",
      "   -1.2128159e+00 -1.8676190e+00]\n",
      "  [ 8.6757622e+00 -1.8588327e+00 -2.2637541e+00 ... -1.1624765e+00\n",
      "   -1.2762370e+00 -1.4709924e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[ 4.4714441e+00  2.6543674e-01 -1.0954884e+00 ... -8.6127478e-01\n",
      "   -1.5749955e-01 -2.6510355e+00]\n",
      "  [ 9.0881948e+00 -1.5009668e+00 -1.9254508e+00 ... -1.3495163e+00\n",
      "   -1.6390302e+00 -2.0563157e+00]\n",
      "  [-2.4809415e+00  7.0502477e+00 -1.0807505e+00 ... -8.2349193e-01\n",
      "   -2.4597093e-01 -3.5949492e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[ 2.5237868e+00 -5.5672374e-02 -1.2860067e+00 ... -4.8923236e-01\n",
      "   -4.0342316e-01 -9.4781572e-01]\n",
      "  [ 8.1655397e+00 -1.3638088e+00 -1.9791485e+00 ... -1.2491256e+00\n",
      "   -1.4780415e+00 -2.3101692e+00]\n",
      "  [ 7.5616994e+00 -1.0550755e+00 -1.9521006e+00 ... -1.0483080e+00\n",
      "   -1.1994048e+00 -2.4665101e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 3.6891801e+00 -8.2583547e-01 -2.1547570e+00 ...  1.5305836e-01\n",
      "   -3.8366926e-01 -1.2899485e+00]\n",
      "  [ 8.8623972e+00 -1.5224245e+00 -2.1854610e+00 ... -1.4254843e+00\n",
      "   -1.1844246e+00 -2.3830993e+00]\n",
      "  [ 8.8321037e+00 -1.7448608e+00 -1.9432402e+00 ... -1.4520254e+00\n",
      "   -1.2903996e+00 -2.0282674e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[ 5.1923676e+00 -1.3173833e+00 -2.6510220e+00 ... -1.1315459e+00\n",
      "    4.1050065e-01 -1.2862093e+00]\n",
      "  [ 8.9584837e+00 -1.6838723e+00 -2.1986024e+00 ... -1.3273945e+00\n",
      "   -1.2440498e+00 -2.1954415e+00]\n",
      "  [ 3.8915343e+00 -1.0297887e+00 -3.8308206e+00 ... -2.0299768e+00\n",
      "    2.9487720e+00 -8.8600081e-01]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[ 1.5326436e+00 -9.1274458e-01 -1.6801529e+00 ... -8.3743656e-01\n",
      "    6.6294599e-01  9.3038118e-01]\n",
      "  [-1.8795880e+00 -6.4064753e-01 -3.5937848e+00 ... -1.3071610e+00\n",
      "    6.9055691e+00 -6.1954218e-01]\n",
      "  [-1.4183700e+00 -3.2227035e+00 -1.1854427e+00 ...  6.3958216e-01\n",
      "    1.4112672e+00  6.2702198e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/raj/.cache/huggingface/datasets/xtreme/PAN-X.fr/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-e0f733454a77c6e3.arrow\n",
      "Loading cached processed dataset at /home/raj/.cache/huggingface/datasets/xtreme/PAN-X.fr/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-428c0ad2f890b9e4.arrow\n",
      "Loading cached processed dataset at /home/raj/.cache/huggingface/datasets/xtreme/PAN-X.fr/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-4595e33651fa990a.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of [de-fr] model on [de] dataset: 0.864\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_pred.predictions  [[[ 1.2788754e+00  1.0256761e-01 -7.1424395e-01 ... -3.1762287e-01\n",
      "   -4.9012980e-01 -4.5980361e-01]\n",
      "  [ 8.0796852e+00 -1.5753639e+00 -1.5942718e+00 ... -1.0868329e+00\n",
      "   -1.4891094e+00 -2.2354872e+00]\n",
      "  [ 8.2575998e+00 -1.5682460e+00 -1.6538008e+00 ... -8.9613837e-01\n",
      "   -1.6109847e+00 -2.2690578e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[ 1.6414437e+00 -5.4920310e-01 -1.4428914e+00 ... -6.9410306e-01\n",
      "    2.9149535e-01  7.4250735e-02]\n",
      "  [ 7.6763973e+00 -1.5559667e+00 -2.3128316e+00 ... -1.9272563e+00\n",
      "   -6.5767646e-01 -2.4658213e+00]\n",
      "  [ 7.6598663e+00 -1.9512451e+00 -2.2052319e+00 ... -1.7926939e+00\n",
      "   -7.4470687e-01 -2.1214256e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[ 4.3547454e+00  1.2898420e+00  1.2959979e-01 ... -1.7702529e+00\n",
      "   -5.1262540e-01 -3.0157831e+00]\n",
      "  [ 8.8648462e+00 -1.4239770e+00 -1.6714712e+00 ... -1.4508555e+00\n",
      "   -1.7157501e+00 -2.1258996e+00]\n",
      "  [ 8.3628778e+00 -4.9439204e-01 -2.4869294e+00 ... -1.8414457e+00\n",
      "   -9.8659641e-01 -2.4729698e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 9.1394252e-01 -4.0479058e-01 -9.7000271e-01 ...  6.3674623e-01\n",
      "   -5.4417425e-01  1.2564700e-03]\n",
      "  [ 7.4586916e+00 -1.8930858e+00 -1.1066658e+00 ... -3.5323226e-01\n",
      "   -2.0958376e+00 -2.2048347e+00]\n",
      "  [-1.7007848e+00  1.2986138e+00 -3.3605385e+00 ... -1.2680362e+00\n",
      "    2.7229805e+00 -3.0625904e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[ 2.3502815e+00 -9.6334124e-01 -1.3120904e+00 ...  2.1365712e+00\n",
      "   -8.8757104e-01 -2.0815935e+00]\n",
      "  [-9.8733729e-01  4.7567129e-01 -2.8657072e+00 ...  1.7909382e-01\n",
      "    3.0437040e-01 -3.9817169e+00]\n",
      "  [-4.5553279e-01 -2.6461823e+00 -1.0829005e+00 ...  5.1061473e+00\n",
      "   -2.3393080e+00 -1.3936074e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[ 1.8079330e+00  6.7613500e-01 -4.4103315e-01 ... -6.7800027e-01\n",
      "   -6.1847788e-01 -1.2183619e+00]\n",
      "  [ 8.2915936e+00 -1.5888315e+00 -1.5104959e+00 ... -1.1753095e+00\n",
      "   -1.6423048e+00 -2.2742689e+00]\n",
      "  [ 8.3877096e+00 -1.5589392e+00 -1.5953176e+00 ... -1.0490295e+00\n",
      "   -1.7790606e+00 -2.3247764e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/raj/.cache/huggingface/datasets/xtreme/PAN-X.it/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-0aca5f2553f92f34.arrow\n",
      "Loading cached processed dataset at /home/raj/.cache/huggingface/datasets/xtreme/PAN-X.it/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-6600f7a976c53871.arrow\n",
      "Loading cached processed dataset at /home/raj/.cache/huggingface/datasets/xtreme/PAN-X.it/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-838480ede753f20c.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of [de-fr] model on [fr] dataset: 0.853\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_pred.predictions  [[[ 3.7166357e+00 -1.2619112e+00 -2.2557929e+00 ...  5.6298733e-01\n",
      "    1.1598121e-01 -5.2288496e-01]\n",
      "  [ 8.6381283e+00 -1.8671875e+00 -2.1196425e+00 ... -1.4462342e+00\n",
      "   -9.8055744e-01 -2.2343080e+00]\n",
      "  [ 8.3918514e+00 -2.1022918e+00 -2.3110900e+00 ... -1.1444126e+00\n",
      "   -7.0494413e-01 -1.8374062e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[ 4.4032230e+00 -1.8947252e+00 -2.6837313e+00 ... -1.4222655e+00\n",
      "    1.0620900e+00  1.1252093e+00]\n",
      "  [ 8.3659286e+00 -1.7641534e+00 -2.1449032e+00 ... -1.3957684e+00\n",
      "   -9.5517170e-01 -1.9215144e+00]\n",
      "  [ 8.7616568e+00 -2.1901000e+00 -1.9285494e+00 ... -8.8651001e-01\n",
      "   -1.7049687e+00 -1.3584644e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[ 1.1992844e+00 -4.9601603e-01 -8.8572359e-01 ...  1.8520231e+00\n",
      "   -8.0047959e-01 -6.2346888e-01]\n",
      "  [-1.5624248e+00  2.3648818e+00 -2.2809994e+00 ... -7.3627883e-01\n",
      "    9.7714186e-01 -3.5583344e+00]\n",
      "  [-1.6937784e+00 -2.3789194e+00  1.3547962e+00 ...  5.5481420e+00\n",
      "   -2.8649192e+00  7.5283855e-01]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 1.1158568e+00  5.5675350e-02 -5.9508991e-01 ... -3.0520928e-01\n",
      "   -5.0400782e-01 -3.9331496e-01]\n",
      "  [ 6.2105198e+00 -6.8053722e-01 -2.9355733e+00 ... -1.5475307e+00\n",
      "   -8.3361872e-02 -2.9993846e+00]\n",
      "  [ 6.3659019e+00 -2.2110960e+00 -1.8132753e+00 ... -6.5277076e-01\n",
      "   -1.4484191e+00 -1.6019244e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[ 1.4752253e+00 -9.4644582e-01 -1.0627655e+00 ...  2.5960553e+00\n",
      "   -7.3057479e-01 -1.7390584e+00]\n",
      "  [ 2.1607889e-01 -3.2506120e-01 -3.2212665e+00 ... -5.8467586e-02\n",
      "    2.4104485e-01 -3.2605379e+00]\n",
      "  [ 5.7138366e-01 -1.9971648e+00 -2.1152289e+00 ...  2.8779719e+00\n",
      "   -1.3987474e+00 -1.9670881e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]\n",
      "\n",
      " [[-8.6604869e-01 -1.5872756e-01  1.1293766e+00 ...  1.0593536e+00\n",
      "   -1.2872605e-01 -5.0518608e-01]\n",
      "  [-9.0740639e-01  2.7637050e+00 -2.8962979e+00 ... -1.8752238e+00\n",
      "    1.4496340e+00 -3.9123390e+00]\n",
      "  [-1.0541823e+00 -2.7336648e+00  3.0943048e+00 ...  4.8976364e+00\n",
      "   -2.9520702e+00  1.0259280e+00]\n",
      "  ...\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]\n",
      "  [-1.0000000e+02 -1.0000000e+02 -1.0000000e+02 ... -1.0000000e+02\n",
      "   -1.0000000e+02 -1.0000000e+02]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/raj/.cache/huggingface/datasets/xtreme/PAN-X.en/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-85e11aea0c209c3a.arrow\n",
      "Loading cached processed dataset at /home/raj/.cache/huggingface/datasets/xtreme/PAN-X.en/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-4d29ec81a064ef61.arrow\n",
      "Loading cached processed dataset at /home/raj/.cache/huggingface/datasets/xtreme/PAN-X.en/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-4c06b3c347f3c313.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of [de-fr] model on [it] dataset: 0.801\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_pred.predictions  [[[ 5.42772484e+00 -1.14976752e+00 -2.47005749e+00 ... -8.94829690e-01\n",
      "    3.69182825e-01 -2.07568240e+00]\n",
      "  [ 8.96281528e+00 -1.86973000e+00 -1.72235703e+00 ... -1.12721860e+00\n",
      "   -1.59222066e+00 -2.01083302e+00]\n",
      "  [ 8.92686749e+00 -2.17295671e+00 -1.84569728e+00 ... -9.90983546e-01\n",
      "   -1.57947874e+00 -1.61154556e+00]\n",
      "  ...\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]]\n",
      "\n",
      " [[ 1.81065786e+00  1.89489579e+00  1.40676618e+00 ... -1.45626545e+00\n",
      "   -3.41588467e-01 -2.74682546e+00]\n",
      "  [-1.22674024e+00  8.10274792e+00 -7.53084064e-01 ... -1.53944945e+00\n",
      "   -8.67390633e-01 -3.51252913e+00]\n",
      "  [-1.86238158e+00 -4.87005949e-01  7.45576572e+00 ...  8.61150742e-01\n",
      "   -2.64542413e+00 -1.39375198e+00]\n",
      "  ...\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]]\n",
      "\n",
      " [[-1.16185296e+00 -6.33555353e-01 -9.53152776e-01 ...  2.68490553e+00\n",
      "   -8.20100129e-01 -4.59080845e-01]\n",
      "  [-1.78562319e+00  1.73193502e+00 -3.11350369e+00 ... -8.45595062e-01\n",
      "    1.59959245e+00 -3.60402536e+00]\n",
      "  [-1.62029588e+00  1.09233409e-01 -1.98646092e+00 ...  1.27966809e+00\n",
      "   -2.23490626e-01 -2.26070261e+00]\n",
      "  ...\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-8.13643694e-01  7.19134688e-01  1.56196201e+00 ...  3.80319431e-02\n",
      "    9.54886675e-02 -9.53659475e-01]\n",
      "  [-2.02549148e+00  7.94793558e+00 -6.33714676e-01 ... -1.31395113e+00\n",
      "   -7.29433119e-01 -3.29508924e+00]\n",
      "  [-1.31387424e+00 -8.00155103e-01  7.12755299e+00 ...  8.92840326e-01\n",
      "   -2.98067164e+00 -1.34363377e+00]\n",
      "  ...\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]]\n",
      "\n",
      " [[ 1.45451963e+00 -8.10494423e-01 -1.35062122e+00 ... -2.55664319e-01\n",
      "    5.73691400e-03  7.57720470e-01]\n",
      "  [ 8.08500481e+00 -1.68021488e+00 -1.74782503e+00 ... -1.05998647e+00\n",
      "   -1.78456151e+00 -2.36996365e+00]\n",
      "  [ 8.14930153e+00 -1.49146676e+00 -1.90396976e+00 ... -1.15206861e+00\n",
      "   -1.68166673e+00 -2.22440696e+00]\n",
      "  ...\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]]\n",
      "\n",
      " [[ 1.49573755e+00 -8.51834357e-01 -1.47014368e+00 ...  7.64865577e-01\n",
      "   -4.55910742e-01 -5.56891263e-01]\n",
      "  [-9.64422449e-02  3.24652307e-02 -3.04838800e+00 ... -2.53912807e-01\n",
      "    1.77465665e+00 -3.16574693e+00]\n",
      "  [-5.30208111e-01 -2.99011517e+00 -1.05114385e-01 ...  4.74328566e+00\n",
      "   -1.62871122e+00  8.33803654e-01]\n",
      "  ...\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]\n",
      "  [-1.00000000e+02 -1.00000000e+02 -1.00000000e+02 ... -1.00000000e+02\n",
      "   -1.00000000e+02 -1.00000000e+02]]]\n",
      "F1-score of [de-fr] model on [en] dataset: 0.674\n"
     ]
    }
   ],
   "source": [
    "for lang in languages:\n",
    "    f1 = evaluate_lang_performance(lang, trainer)\n",
    "    print(f\"F1-score of [de-fr] model on [{lang}] dataset: {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "corpora = [panx_de_encoded]\n",
    "\n",
    "# Exclude German from iteration\n",
    "for lang in languages[1:]:\n",
    "    training_args.output_dir = f\"xlm-roberta-base-finetuned-panx-{lang}\"\n",
    "    # Fine-tune on monolingual corpus\n",
    "    ds_encoded = encode_panx_dataset(panx_ds_combined[lang])\n",
    "    metrics = fine_tuning_training_on_single_corpus(ds_encoded, ds_encoded[\"train\"].num_rows)\n",
    "    # Collect F1-scores in common dict\n",
    "    f1_scores[lang][lang] = metrics[\"f1_score\"][0]\n",
    "    # Add monolingual corpus to list of corpora to concatenate\n",
    "    corpora.append(ds_encoded)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multilingual Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpora_encoded = concatenate_splits(corpora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args.logging_steps = len(corpora_encoded[\"train\"]) // batch_size\n",
    "training_args.output_dir = \"xlm-roberta-base-finetuned-panx-all\"\n",
    "\n",
    "trainer = Trainer(model_init=model_init, args=training_args,\n",
    "    data_collator=data_collator, compute_metrics=compute_metrics,\n",
    "    tokenizer=xlmr_tokenizer, train_dataset=corpora_encoded[\"train\"],\n",
    "    eval_dataset=corpora_encoded[\"validation\"])\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_data = {\"de\": f1_scores[\"de\"],\n",
    "               \"each\": {lang: f1_scores[lang][lang] for lang in languages},\n",
    "               \"all\": f1_scores[\"all\"]}\n",
    "f1_scores_df = pd.DataFrame(scores_data).T.round(4)\n",
    "f1_scores_df.rename_axis(index=\"Fine-tune on\", columns=\"Evaluated on\",\n",
    "                         inplace=True)\n",
    "f1_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluated on -->\tde\tfr\tit\ten\n",
    "# Fine-tune on   \n",
    "# de\t        0.8691\t0.7016\t0.6739\t0.5921\n",
    "# each\t        0.8691\t0.8372\t0.8178\t0.7084\n",
    "# all\t        0.8697\t0.8729\t0.8698\t0.7724"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "raj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
